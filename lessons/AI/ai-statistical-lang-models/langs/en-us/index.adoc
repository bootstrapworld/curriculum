[.beta]
= Statistical Language Modeling: AI-generated text

@description{Students consider how statistics and probability drive AI text generation, learning that language models can produce text that sounds credible but may not actually be credible.}

@lesson-prereqs{ai-training-2-dimensionality-natural-language}

@keywords{}

[@lesson-intro-table]
|===
| Lesson Goals
| Students will be able to...

@objectives

| Student-facing Lesson Goals
|

- Let's explore how probability influences the output of generative AI models.


| Materials
|[.materials-links]
@material-links

| Preparation
| @preparation{
- Make a copy of the @online-exercise{https://docs.google.com/forms/u/1/d/1C1WSad_IrVT0pd_IXG7yCCM30CVoIibv9kBDKnEJ5RI/copy, What comes next? Survey Google Form} so that you can examine your class's data. _If you are using our Google Slides, be sure to add the link to your copy of the form to the appropriate slide._}

|===



== Introduction to Statistical Language Modeling

@objective{predictive-text}

=== Overview

Students explore how text prediction relies on statistical language modeling.

=== Launch
@slidebreak{Launch}

While texting, emailing, or even conducting a web search, you've probably noticed that your thoughts and sentences are sometimes finished for you! Predictive text is now a common feature of many apps, and it is made possible by a certain form of AI: the @vocab{statistical language model}.

@teacher{
Make sure you've made a copy of the @online-exercise{https://docs.google.com/forms/u/1/d/1C1WSad_IrVT0pd_IXG7yCCM30CVoIibv9kBDKnEJ5RI/copy, survey} and have created a link to share with students, so that you can look at your data as a class!
}

@slidebreak{Launch}

@lesson-instruction{
- Consider this start of a phrase: "Close the..."
- Use the form to record the next word that pops into your mind.
- Type in two other possible next words.
}

@teacher{
Display the survey results for the class to see. If a word is repeated, summarize the results by keeping a tally of how many students suggest each particular word.

Students will think of words like "door", "box", "microwave", "laptop"...
}

=== Investigate
@slidebreak{Investigate}

Let's look a little more closely at the words we generated.

@QandA{
@Q{Which words were suggested most often?}
@Q{Which words were suggested least often?}
@Q{Are you surprised by the most and least common words? Why or why not?}
@Q{What fraction of our class proposed each of our top three words?}
@A{For example: If there are 25 students in your class, and 8 students chose “door”, it was chosen 8/25ths of the time.}
}

@slidebreak{Investigate2}

Statistical lanuage models are built on the assumption that the fraction of the time that a word follows a series of words in a training corpus can help predict the likelihood of it being the right word to follow that same series of words in a future scenario. In this lesson, we will refer to that fraction as its @vocab{probability}.

@QandA{
@Q{Do you think a text messaging app with a predictive text feature would produce the same results as our class? Why or why not?}
@A{Answers will vary. Invite conversation.}
@A{An app will probably not suggest all the same words.}
@A{Our class is a pretty small sample, all from the same generation and geography and we are all currently at school so our minds are primed to respond differently than if we were somewhere else.}
}

@slidebreak{Investigate}

Similar to other AI systems we've discussed, predictive text features are trained on a large amount of data, in this case, text.

During training:

1. The computer extracts each use of the phrase "Close the" from the training dataset, along with the subsequent word.
2. It then determines the probability of each possible next word.

@ifnotslide{@right{@image{images/texting-app.png, 200}} When making a suggestion: 

@hspace{1em}It offers the words that had the highest probability of following "Close the" in the training dataset.

Consider this screenshot from a text messaging app. +  
In the @vocab{training corpus} it was built on, "door", "doors", and "house"  most commonly appeared after "Close the". +
As a result, those words are suggested. +
But are all users recommended the _same_ completions?
}

@ifslide{When making a suggestion: 

@hspace{1em}It offers the words that had the highest probability of following "Close the" in the training dataset.

@slidebreak{InvestigateR}

@image{images/texting-app.png, 200}
Consider this screenshot from a text messaging app. +  
In the @vocab{training corpus} it was built on, "door", "doors", and "house"  most commonly appeared after "Close the". +
As a result, those words are suggested. +
But are all users recommended the _same_ completions?
}

@slidebreak{Investigate}

@QandA{
@Q{What do you think? Will your phone suggest the same words as your classmates' phones would? Why or why not?}
@A{Before we get into the in-depth student-facing explanation, below, invite discussion!}
@A{This question is a great opportunity to revisit previous concepts, in particular the process of training and sampling that students discussed when thinking about @lesson-link{ai-training-bag-of-words, "plagiarism detection"}.}
}

@slidebreak{Investigate}

For a variety of reasons, not all phones will propose the same completions:

- There might be multiple words with equal probability, in which case the system must use some method of random selection. As a result, even the same phone won't necessarily propose the same word every time.
- Not all phones use the same system. Systems are generally built with at least a little bit of randomness; the amount of randomness varies from system to system.
- A messaging app also includes a model of the text that _the actual user_ composes. The app therefore offers a degree of personalization based on what the user has chosen in the past. Similarly, the app can take into account the word suggestions that you have previously accepted.
- Some predictive text features even take into account the specific message that you are composing! For instance, typing first letter of an unusual word that you used in the same message triggers the app to propose that unusual word.

@slidebreak{Investigate}

@QandA{
@Q{We just considered four reasons why different phones sometimes propose different completions. Do each of these four reasons represent _statistical_ phenomena? Why or why not?}
@A{Phenomena 1 and 2 are statistical, given that statistical language modeling always includes some element of randomness.}
@A{Phenomena 3 demonstrates the use of a _personalized_ language model, a more refined version of a statistical language model.}
@A{Phenomena 4 is almost anti-statistical! The AI consumes and uses data outside of the model for the corpus.}
}

Phenomena 3 and 4 above suggest that sometimes making a usable tool requires that we step out of bounds! Although pure statistical language models are powerful, the upgrades that programmers develop can make the AI _better_ at completing the task that it was designed to complete.

@slidebreak{Investigate}

You have just considered the workings and in-context use of a @vocab{statistical language model}. Hopefully you have discovered that, although it sometimes may _seem_ like your texting app can read your mind... it can't. It doesn't know the rules of grammar, the meanings of words, or your intentions when you are composing a text. It just knows @vocab{probability}, which it uses in ways that are often very impressive (but sometimes not!).

@teacher{
Throughout the lesson, we'll explore the very important "sometimes not" parenthetical, above.}

=== Synthesize
@slidebreak{Synthesize}

@QandA{

@Q{Might statistical language modeling be possible for other spoken human languages? Which languages?}
@A{Statistical language modeling will work for any language! The AI does not need to "know" anything about the rules of grammar; it just follows rules that enable it to identify patterns.}

@Q{Can you think of other things besides human spoken languages that a similar approach might work for?}
@A{With statistical language modeling, AI can compose music, play chess games, and more. The "text" does not need to be made up of words: any symbolic notation at all will do as long as it uses spaces to separate the symbolic "words".}
}

== Constructing a Statistical Language Model

@objective{slm}

=== Overview

Students construct a statistical language model by decomposing the text and computing the probabilities of different words following each other.

=== Launch
@slidebreak{Launch}

The best way to make sense of statistical language modeling is to try it yourself! We'll start by constructing a model.

For our corpus, we will use the folk song @handout{old-lady-lyrics.adoc, "There Was an Old Lady Who Swallowed a Fly"}, which tells the nonsensical story of an old lady who swallows a fly, and the unfortunate series of events that follow.

@slidebreak{Launch}

First, we will decompose the title of our corpus into differently sized chunks (one word at a time, two words at a time, etc.):

[cols="^.^1,^.^1,<.^8", stripes="none", options="header"]
|===

| chunk size | Quantity			| Decomposition

| 1 word
| 9
| (There) (Was) (an) (Old) (Lady) (Who) (Swallowed) (a) (Fly)

| 2 words
| 8
| (There Was) (Was an) (an Old) (Old Lady) (Lady Who) (Who Swallowed) (Swallowed a) (a Fly)

| 3 words
| 7
| (There Was an) (Was an Old) (an Old Lady) (Old Lady Who) (Lady Who Swallowed) (Who Swallowed a) (Swallowed a Fly)

|===

The formal word computer scientists use in this context is not "chunk" but @vocab{n-gram}. In an @math{n}-gram, @math{n} represents the number of words in the chunk. For special cases where @math{n} is 1, 2, or 3, the @math{n}-grams are called @vocab{unigrams}, @vocab{bigrams}, and @vocab{trigrams}.

@QandA{
@Q{What other collections of words have you encountered that begin with "uni", "bi", and "tri"?}
@A{Answers will vary!}
@A{unicycle, bicycle, tricycle}
@A{(monomial), binomial, trinomial...}
@A{triangle, n-gon}
@A{biceps, triceps, (quadriceps)}
@A{unicorn}

}

=== Investigate
@slidebreak{Investigate}

Let's dig a little deeper...

@teacher{
Share the @handout{old-lady-lyrics.adoc, song lyrics} with students to read independently. If desired, you could also listen to a recorded version of the song.
}

The phrase "there was an old lady who swallowed a..." is repeated in our corpus! Let's zoom in on one unigram from that phrase: “there”.

@QandA{
@Q{Referring to the corpus (the @handout{old-lady-lyrics.adoc, "lyrics"} *and the title*: how many times does the word "there" appear in the song?}
@A{5}
@Q{In this corpus, how many times was the word "there" followed by the word "was"?}
@A{5}
@Q{What is the probability that the word "there" is followed by the word "was"?}
@A{5/5 or 100%}
}


@slidebreak{Investigate}

In the example you just worked through, you computed the probability that "was" appears after the unigram "there"...

@indented{by dividing 5 _(how many times we see "there" followed by "was")_ by 5 _(how many times we see "there" followed by anything)_.}

We can represent this computation with a special notation:

@indented{
@math{p(was | there) =}
@math{\frac
	{\textit{count(there was)}}
	{\textit{count(there...)}} = {\frac{5}{5}}}
}

@lesson-instruction{
- Complete @printable-exercise{constructing-model.adoc}.
}



@slidebreak{Investigate}

@QandA{

@Q{What @vocab{training corpus} did we use to construct the language model?}
@A{The song lyrics, including the title of the song, were our corpus.}

@Q{Make a prediction: How can we make use of the ratios we completed on @printable-exercise{constructing-model.adoc}?}
@A{We can refer to our ratios to determine which word is the most likely to follow a given word.}

}

@teacher{
Are you and your students interested in exploring probability in more depth? Check out our lesson on @lesson-link{probability-inference} to dig deeper.
}

=== Synthesize
@slidebreak{Synthesize}

@QandA{
In our song corpus, 

- there were _four_ possible completions for the unigram "the"
- there were only _three_ possible completions for the 3-gram "to catch the"

We can say that, _in this corpus_, as the n-gram gets longer, the number of completion options decreases.

@Q{Do you think it will generally be true of other corpuses that as the n-gram gets longer, the number of completion options decreases?}
@A{Yes, in general, this is a true statement: longer phrases have fewer possible completions than single words.}
}

== Sampling from the Model

=== Overview

Students use their statistical language model in a generative way, to produce output.

=== Launch
@slidebreak{Launch}

Having built a language model, what can we do with it? We can use it in a generative way: we can produce output!

How might we go about doing that?

- We can start by choosing our first word. A common approach is to ask, "What's the most common @math{n}-gram in the corpus?" but we can also choose the starting word on our own, if we want.
- Next, we ask: "Given the first @math{n}-gram, what is the most common successor?"
- We repeat this second step forever! ...or, more realistically, until we decide to stop the program. A simple statistical language model, however, will generate text ad infinitum.

=== Investigate
@slidebreak{Investigate}

Let's give this process a try, returning to our "Old Lady" corpus.

@teacher{Note that on @printable-exercise{sampling.adoc}, questions build on one another. In other words, a student who misses Question 2 will also get Question 3 incorrect. To ensure that class runs smoothly, we encourage you to require that students check their work with a partner before moving from one question to the next. Encouraging students to annotate @handout{old-lady-lyrics.adoc} will also result in more accurate counting and therefore more correct responses!}

@lesson-instruction{

- Complete the first section of @printable-exercise{sampling.adoc} using @handout{old-lady-lyrics.adoc}.
- Tip: Annotate your @handout{old-lady-lyrics.adoc}! Highlighters and different colors of ink can help you to stay organized.
}

@teacher{The two questions below are on students' worksheets, but merit follow-up and discussion.}

@QandA{
@Q{What four-word phrase did you generate?}
@A{"She swallowed a fly"}

@Q{Did everyone in your class end up with same phrase? How and why did that happen?}
@A{Yes. When considering which word to generate next, there was always one word that was clearly the most probable, and there were no ties.}
}


@slidebreak{Investigate}

@lesson-instruction{
- Complete the second section of @printable-exercise{sampling.adoc}.
}

@QandA{
@Q{What four-word phrase did you generate for *Text Generation 2a*?}
@A{The class should be split between "the spider to catch" and "the spider that wriggled".}

@Q{Why didn't everyone end up with the same phrase?}
@A{We were forced to incorporate randomness when there was a tie for the most probable word to follow "spider".}
}


@slidebreak{Investigate}

Modern statistical language models often invite users to adjust the @vocab{temperature} of the generated text, which influences the level of randomness. For instance, ChatGPT users are encouraged to use a _low_ temperature for more focused and less creative tasks. They are encouraged to use a _higher_ temperature for more random and increasingly creative tasks.

@lesson-point{
Temperature is the parameter that controls the randomness of the model's output as it generates text.
}

Even _without_ the ability to raise the temperature, we encountered randomness and variability in our generated texts. With a large enough corpus and a high enough temperature, a statistical language model will produce a new and unique output every single time!

@strategy{AI "Hallucinations"}{

As generative AI produces text, it often generates incorrect or misleading information. This is commonly known as an AI "hallucination".

Some experts dislike this term and are encouraging an end to its use. These experts argue that _all_ output is "hallucinatory". Some of it happens to match reality... and some does not.

The very same process that generates "hallucinatory" text _also_ generates the "non-hallucinatory" text. This truth helps us to understand _why_ it is so difficult to *fix* the "hallucination" problem.

This term also attributes intent and consciousness to the AI, giving it human qualities when it is merely executing a program exactly as it is intended to do.
}

=== Synthesize
@slidebreak{Synthesize}

@QandA{
Critics of ChatGPT and other language models raise a variety of concerns. Consider each of them, below.

@Q{ChatGPT sometimes "makes stuff up." Why does this happen? What is actually going on?}
@A{When ChatGPT produces false or misleading information, it is not glitching nor is there a bug. ChatGPT is just doing what it does, following the model as it ought to.}

@Q{ChatGPT has biases that can be seen in its text output. Where do these biases come from?}
@A{If there are biases in the corpus, there will likely be biases in the output!}
}
