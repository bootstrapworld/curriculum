= Decision Tree: Predicting Shopping Behavior -- Part 1

++++
<style>
/* Shrink vertical spacing on fitbruby */
.fitbruby{padding-top: 0.3rem; padding-bottom: 0.3rem}
</style>
++++

[.data-table, cols="2,2,3,2,2", stripes="none", options="header"]
|===
| name 		| age      | shopping history 	|  interest in game | buys game
| Jan 		| teens    | previous customer 	| no  				| no
| Jose 		| teens    | previous customer 	| no 				| no
| Maribel 	| twenties | previous customer  	| no  				| yes
| Noah		| thirties | previous customer	| no  				| yes
| Sydney 	| thirties | previous customer 	| yes 				| yes
| Mariana 	| thirties | new customer 		| yes 				| no
| Rasula	| twenties | new customer 		| yes 				| yes
| Jillian	| teens    | previous customer 	| no 				| no
| Ariella	| teens    | new customer  		| yes  				| yes
| Isabela	| thirties | previous customer	| yes 				| yes
| Danial	| teens    | previous customer 	| yes 				| yes
| Kate		| twenties | previous customer	| no 				| yes
| Taikhoom	| twenties | previous customer 	| yes  				| yes
| Peter 	| thirties | new customers		| no 				| no
|===

== "Age" as the Root Node

The @vocab{decision stump} below splits the above training data by age and indicates whether the individuals in each group buy the game. 

@ifnotsoln{@center{@image{../images/stump.png, 180}}}

@ifsoln{@center{@image{../images/age-stump-checks.png, 170}}}

@teacher{Students won't see the check marks -- they will add them in question 3.}

@n Where do the Y/N lists beneath each of the three branches come from? @fitb{}{}

@fitb{}{@ifsoln{ 2 of the 5 teens bought the game, 4 of the 4 people in their twenties bought the game, and 3 of the 5 people in their thirties bought the game.}}

@n What prediction will our current model (decision stump) make for each group?

@indented{
- people in their teens @fitbruby{15em}{@ifsoln{will not}}{will / will not} buy the game
- people in their twenties @fitbruby{15em}{@ifsoln{will}}{will / will not} buy the game
- people in their thirties @fitbruby{15em}{@ifsoln{will}}{will / will not} buy the game
}

@n Place checkmarks below each of the values in the stump leaves for which our prediction is correct.

@n Find the likelihood of a correct prediction for each age group. 
@hspace{2em} teens: 	@fitb{3em}{@ifsoln{60}}%
@hspace{2em} twenties: @fitb{3em}{@ifsoln{100}}%
@hspace{2em} thirties:@fitb{3em}{@ifsoln{60}}%

@n How accurate is the current prediction across our entire dataset? @hspace{1em} @fitb{1em}{@ifsoln{10}} _correct predictions out of 14 attempts._ (@fitb{1em}{@ifsoln{71}} % accuracy).

== Improving Our Prediction

We made our prediction without considering all of the columns in our training data. If we add another level to our tree, we might be able to improve our accuracy!

@n Before moving on to the second level of his decision tree, Ernie removed all of the rows for people in their twenties. Bert said, _"I don't think that's a good idea! Why would we alter our dataset just because we're starting the second level of the tree?"_ Explain Ernie's (correct) decision to Bert. @fitb{}{@ifsoln{Since all customers in their twenties buy the game, it's a leaf node, which means there won't be any branches}} +
@fitb{}{@ifsoln{for these rows to train the AI to make decisions for.}}

@n We used "age" as our root node. What questions could we ask at our second-level decision node? @fitbruby{8em}{@ifsoln{interest in game}}{[column]} or @fitbruby{8em}{@ifsoln{shopping history}}{[column]}


