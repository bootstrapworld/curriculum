[.beta]
= Supervised Learning: Decision Trees

@description{Students explore the technology behind YouTube video recommendations and election outcome predictions. They develop and analyze decision trees to predict individuals’ purchasing decisions.}

@lesson-prereqs{ai-training-bags-of-words}


@keywords{}

[@lesson-intro-table]
|===
| Lesson Goals
| Students will be able to...
@objectives

| Student-facing Lesson Goals
|

- Let's create, use, and understand decision trees, the technology behind YouTube recommendations and election outcome predictions

| Materials
|[.materials-links]
@material-links


|===

== Making Predictions @duration{25 minutes}

@objective{ai-create-tree}

=== Overview

Students consider technologies that make predictions and recommendations, and then play a game to help them build a frame of reference for diagramming the decision-making process.

=== Launch
@slidebreak{Launch}

Consider each of the three situations described below:

- You just finished watching a YouTube video. Another video appears... and it is exactly the kind of video you would want to watch.
- Two individuals who work for the same company and earn the same salary apply for a loan by filling out the same online form at the local bank. One of them is granted a loan, but the other is not.
- A news anchor displays a map with some states colored blue and others colored red. She explains that the map's predictions for the upcoming election were developed using historical census data.

On the surface, these situations may not seem to have a lot in common. If you dig a little deeper, however, you will discover that, in each of these scenarios, a computer uses data to drive the way that it makes recommendations, decisions, and predictions.

@slidebreak{Launch}

@QandA{
@Q{What kind of data do you think is used for recommending videos?}
@A{Viewing history, search history, channel subscriptions, likes, dislikes, google activity, "not interested" feedback}

@Q{What kind of data do you think is used for classifying loan requests?}
@A{Debt, assets, payment history, number of open accounts, delinquent accounts, income/revenue, expenses, overdrafts in the last 90 days}

@Q{What kind of data do you think is used to predict election outcomes?}
@A{Census data including voter race, gender, income level, party affiliation, age, etc.}
}

=== Investigate
@slidebreak{Investigate}

As a class, we are going to play a game to help us understand the sort of thinking that decision trees imitate.

@teacher{The game we are going to play is a simplified version of 20 questions. If students are familiar with 20 questions, discussing the strategies they use when playing the game will help them to make connections.}

@QandA{
@Q{Show of hands: Have you ever played 20 Questions?}
}

@teacher{If the majority of your students haven't played 20 Questions, the discussion questions below are irrelevant; skip straight to the instructions about how our game will work.}

@QandA{
@Q{What are the rules of 20 questions?}
@A{1 player is “it”. They have to think of a secret person, place or thing. The other players can ask up 20 yes or no questions to help them guess the secret person, place, or thing.}

@Q{What strategies do you use when choosing the questions you will ask?}
@A{Ask questions that are likely to eliminate many objects--but be careful! A question that is too narrow could end up resulting in very little information gained.}
@A{Start with questions that will quickly limit possibilities.}
}

@slidebreak{InvestigateR}

@center{@image{images/fork-knife-spoon-mug-plate-cup.jpeg, 350}}

@lesson-instruction{

We're going to play a modified version of that game. Here's how it works:

- In our game there are six possible categories: *spoon, knife, cup, plate, fork, and mug*.
- I will write one of them down on a piece of paper.
- You will ask me yes/no questions (however many you need!) until you figure out how to categorize the object that I chose.
- As you ask questions, I will record them in a diagram on the board.
}

@teacher{

@right{@image{images/spoon-game.png, 150}}

The first round of this game will produce a diagram similar to the one on the right, which models a game with the secret word "spoon".  The number of questions required to "guess" the object--most likely between two and four--will depend on what your students ask.

Important diagramming conventions:

- Be sure to label arrows with "yes" or "no".
- "Yes" arrows point to the left, and "no" arrows point to the right. 

As students ask questions, support them in noticing how effective their questions are in sorting the items on the list. "Does it have a handle?" split the list between two options that do not have handles (cup, plate) and four that do (spoon, knife, fork, and mug). Other questions could have guaranteed eliminating three choices (half!).

Debrief the activity by posing the questions below. Note that the provided answers correspond with the sample diagram (on the right). Adjust responses to match the diagram that your class produces!
}

@slidebreak{Investigate}

@QandA{
@Q{How many questions did we ask in order to determine how to correctly categorize the object?}
@A{This answer will depend on what your students ask!}
@A{In the example sequence we've diagrammed above, there were 4 questions.}

@Q{Which items from our original list (spoon, knife, cup, plate, fork, and mug) did our very first question eliminate from the list of possibilities?}
@A{This answer will depend on what your students ask!}
@A{In the example sequence we've diagrammed above, there are four items on the list with handles (spoon, knife, fork, and mug). That means our first question--"does it have a handle?" eliminated two items, cup and plate.}

@Q{Can anyone think of a different question that would have eliminated more items right off the bat?}
@A{Responses will vary. "Is it a utensil?" would have split the list in half, given that three items (spoon, knife, and fork) are utensils.}

@Q{How did we decide which questions to ask?}
@A{We had to keep track of which items were eliminated and which items remained in order to pose useful questions.}

@Q{What do you notice and wonder about the diagram I made?}
@A{Each question is in a bubble.}
@A{The questions are connected by arrows, which point left when the answer is "Yes" and right when the answer is "No"}
}

@slidebreak{Investigate}

Let's play _another_ round of the game with a new item. 

@QandA{
@Q{How many questions did we ask in order to determine the correct object this time?}
@Q{How did we decide which questions to ask?}
@Q{Which items from our original list (spoon, knife, cup, plate, fork, and mug) did our very first question eliminate from the list of possibilities?}
@Q{How are the diagrams we drew similar and how are they different?}
}

@slidebreak{Investigate}

Let's imagine that our first round had started with the question, "Is it a utensil?" and had led us to "knife".  After the first round, our diagram might have looked like the diagram on the left (below). If the second round started with the same question, we could have just added to the original diagram... and we might have ended up with something like what you see on the right.

[cols="^.3a,^2a,3a", grid="none", frame="none", stripes="none"]
|===
| @hspace{8em}**Round 1**
|
| @hspace{8em}**Round 2**

| @image{images/tree1.png, 120}
| @image{images/arrow.png, 50}
| @image{images/tree2.png, 370}
|===

@slidebreak{Investigate}

Notice that after Round 2 the topmost question — "is it a utensil?" — splits left ("yes, it is a utensil") *and* right ("no, it is not a utensil"). Our diagram begins with two unique pathways to two unique items. If we were asking categorization questions that were more complex than yes or no questions, we would have more than two unique pathways!

=== Synthesize
@slidebreak{Synthesize}

@QandA{
@Q{If we want to get to the correct categorization as quickly as possible, what would we want to be true about the first question we ask?}
@A{We would want it to split the list of options as evenly as possible to guarantee eliminating a significant number of options right off the bat.}
}


== Decision Trees from Training Datasets @duration{25 minutes}

@objective{ai-create-tree}

=== Overview
Students are introduced to decision trees and how the information contained in them is connected to the table of data they are generated from. 

=== Launch

@slidebreak{Launch}

A @vocab{decision tree} is a model produced by a machine learning algorithm that uses a tree-like model to show decisions and their possible consequences. The diagram of our 20-questions game is a partial decision tree. Many computer programs that make recommendations or predictions utilize decision trees.

Unlike humans, who can generate their own questions, computers generate decision trees from training @vocab{datasets} that contain the answers from a collection of predetermined questions.

Creating a decision trees is a form of @vocab{supervised learning}, because the data the computer is trained on already contains the desired categorizations (tagged by a human), and the computer just learns a function that maps from input to output.

=== Investigate
@slidebreak{Investigate}

@lesson-instruction{
- Let's learn the terminology used to describe decision trees and apply it to the partial decision tree from our 20 questions game.
}
==== Decision Tree Terminology

@right{@image{images/terminology-tree.png, 300}}

- The @vocab{root node} is the very top @vocab{node} that represents the entire population or sample before any splitting occurs.
- @vocab{Splitting} is the process of dividing a node into sub-nodes (decision and/or leaf nodes) with branches. These branches will not necessarily be equal in size.
- @vocab{Decision nodes} split from the root node, or from other nodes.
- A @vocab{leaf node} is a node that does not split. Just like leaves on most trees, leaf nodes are found at the tip of a branch.

@teacher{Discuss the partial decision tree you made during your 20 questions game to help students identify the root node, branches, decision nodes, and leaf nodes on the tree so far.
}

@slidebreak{Investigate}
@lesson-instruction{
- Turn to the first section of @printable-exercise{decision-tree.adoc} and take a few minutes to record your notices and wonderings about how the dataset and decision tree are connected.
}

@slidebreak{InvestigateR}

[.data-table, cols="1,2,2,2,2,2,2", stripes="none", options="header"]
|===
| Item    | flat? | has-handle? | has-tines? | untensil?  | used-to-chop? | category
| A       | no    | yes         | no         | no         | no            | cup
| B       | no    | yes         | yes        | yes        | no            | fork
| C       | yes   | yes         | no         | yes        | yes           | knife
| D       | no    | no          | no         | no         | no            | mug
| E       | yes   | yes         | no         | no         | no            | plate 
| F       | no    | no          | no         | yes        | no            | spoon
| G       | yes   | yes         | no         | yes        | yes           | knife
|===

@center{@image{images/tree4.png, 400}}

@QandA{
Let's think about how the table translates to the tree and then consider how the tree connects back to the table.
@Q{Where do the column headers end up in the tree?}
@A{They are our root and decision nodes.}

@Q{Where do the categories end up in the tree?}
@A{They are our leaf nodes.}

@Q{What rows of the table are we thinking about when the tree asks "used-to-chop?"}
@A{The rows that are utensils.}

@Q{What rows of the table are we thinking about when the tree asks "has-a-handle"?}
@A{The rows that are neither utensils nor flat.}
}

@slidebreak{Investigate}

@lesson-instruction{Turn to the second section of printable-exercise{decision-tree.adoc} and follow the directions to make a new decision tree from the same table, using `flat?` as the root node with `used-to-chop` as the first decision node for "yes" and `utensil?` as the first decision node for "no".}

@slidebreak{Investigate}

[cols="1a,1a"]
|===
|@image{images/tree4.png}
|@image{images/flat-tree-soln.jpeg}
|===

@QandA{
Take a look at the two decision trees we made for this dataset:
@Q{What do these trees have in common?}
@A{They have a root node, 4 decision nodes and 6 leaf nodes.}
@A{They have the same number of levels.}
@A{Each time they fork there are two options: yes/no.}

@Q{How are they different?}
@A{The root node of the first decision tree splits the categories in half so that there are 3 leaf nodes on the left branch and 3 leaf nodes on the right. The root node of the second tree splits the categories into 2 leaf nodes on the left branch and 4 leaf nodes on the right.}
@A{The first decision tree has the same number of levels on the left and right branches, whereas the second decision tree has a shorter left branch than right branch.}
}

@slidebreak{Investigate}

Let's take a step back and see how our decision trees perform with new inputs.

@lesson-instruction{
Complete @printable-exercise{comparing-trees.adoc}.
}

@teacher{
Invite students to share and explain their responses before emphasizing the main ideas, below.
}

@slidebreak{Investigate}

You just observed that a decision tree

- can accurately label and categorize the inputs _that it has been trained to label and categorize_
- can falter when offered inputs that are *unknown*

The only way this tree stands a chance of correctly identifying a chopstick or a spork is if we offer it more training!

@slidebreak{Investigate}

As we built our decision trees, we were able to draw on everything we know about every knife, spoon, spork, plate, bowl or mug that we have ever seen. Our decision trees were imperfect because they didn't know about the utensils we either forgot to include or didn't know about.

If you were asked to create a decision tree to identify common animals or foods, you could probably draw on a wealth of knowledge to create a similarly good one without much difficulty.

@slidebreak{Investigate}

@lesson-point{
When computers build decision trees, they don't have life experience to draw upon. They only use the data we provide... and that data can sometimes be limited or messy! As a result, we may end up with models that are not 100% accurate.
}

=== Synthesize

@slidebreak{Synthesize}

@QandA{
@Q{Will a decision tree always have the same number of leaf nodes as there were rows in the training dataset? Why or why not?}
@A{No. Generally mutliple rows of a training dataset will be assigned the same tag. The training dataset we saw in this lesson section contained multiple knives, for example.}

@Q{Explain how the decision tree and training dataset correspond to each other.}
@A{The column headers from the table are the questions that will get asked in the root and decision nodes of the decision tree.}
@A{The data in each column are the answers to those questions which become the arrow labels of the decision tree (yes and no, for this dataset).}
@A{The output categories from the table are the leaf nodes in the decision tree.}
}


== Decision Stumps: Optimizing Predictions @duration{25 minutes}

=== Overview

Students build a decision tree that predicts whether different individuals will purchase a video game or not.

=== Launch
@slidebreak{Launch}

Have you ever done some online shopping—say, for a new pair of sneakers—only to discover that, for the next several days, you encounter _advertisements for sneakers_ lurking in every corner of the internet that you visit?!

@slidebreak{Investigate}

Websites can store small data files called "cookies" on your device that can be used to remember details like where you were the last time you visited a site. One particular kind of cookie, the tracking cookie, allows AI designed for marketing to use your individual browsing habits to decide which ads you will be the most susceptible to.

But how does the cookie know what you will be susceptible to?  *How do decision trees built from large datasets decide — at every level and every node — which attributes are the most informative ones to ask questions about,* so that they can make relatively accurate predictions, recommendations, and diagnoses?!

It turns out, there's an algorithm for that, and it's relatively straightforward.

=== Investigate
@slidebreak{Investigate}

We're going to create a decision tree that predicts whether or not different customers at a particular online store will purchase a video game or not. To do so, we must first train the computer! We will use a training dataset that characterizes 14 different shoppers and then indicates whether or not each one purchased a video game.

@QandA{
@Q{With your partner, look over the @handout{decision-tree-data.adoc, Training Dataset}. What do you Notice? What do you wonder?}
@A{Possible responses:}
@A{Individuals in their twenties always buy the video game.} 
@A{There are only three new customers; two out of three times, new customers buy the video game.}
@Q{Can you foresee any problems with making a decision tree based on this dataset? If so, what are they?}
@A{Responses will vary.}
@A{We only have data on 14 visitors.}
@A{All of the visitors are between 14 and 38 years old.}
@A{We don't know a lot about their gaming habits.}
}

@slidebreak{Investigate}

@lesson-instruction{
One challenge for processing this dataset is that _age is continuous_ and decision trees are built with _branches_ that grow out of a _decision node_.  We'll need to start by defining discrete age groups.

For now, let’s agree to create three groups: teenagers, twenties, and thirties.
}

@strategy{Why Start the Tree with "Age"?}{
Students will likely notice that we seemingly arbitrarily started the tree with "age" as the root node. _Extremely perceptive_ students may notice that for both "age" and "interest", the likelihood of a correct prediction is 10/14. In other words, starting with "interest in game" produces the same information gain as starting with "age" as the root... *so how do we decide?*

It turns out there's more than one correct way to build a decision tree! In general, however, we want to avoid tall, skinny trees that pose one useless question after the other. Rather, it is beneficial to start with an attribute that will result in a _wider_ tree.

Because the "age" node splits _three_ ways and the "interest in game" node splits _two_ ways, we opt to start the tree with "age".
}

@slidebreak{InvestigateR}

@center{@image{images/stump.png, 180}}

A @vocab{decision stump} is a one-level decision tree that makes a prediction based on the value of just a single input feature.

- First, we list the outcome for each of the individuals in a group's training data.
- Then, we right a rule: which outcome should the computer predict for this group?
- Finally, we calculate what percentage of the rule's predictions are correct for the individuals in our training data.

@lesson-instruction{Let's complete the first section of @printable-exercise{part-1.adoc} together, starting with "age" as the root node.}

- This stump has three branches because we are considering customers in their teens, twenties and thirties.
- The left-most leaf node ("teens") represents the five teens in our training dataset: Jan (16), Jose (19), Jillian (14), Ariella (16), and Danial (19).
** Jan, Jose, and Jillian did *not* purchase the game, so they are represented by the letter N (for "no").
** Ariella and Danial *did* purchase the game, so they are represented by the letter Y (for "yes").
** We illustrate the teens' decisions with the following shorthand: N N N Y Y
- The other leaf nodes similarly summarize the purchasing habits of the individuals in their age groups.

@QandA{
@Q{What else do you notice and wonder about the decision stump?}
@A{Everyone in their twenties bought the game.}
@A{Three out of 5 people in their thirties bought the game.}
@A{On the other decision trees we've seen the arrows were labeled "yes" and "no", but here their labeled "teens", "twenties", "thirties".}
@A{Decision trees usually have a single choice at the end of the arrow, but here we see N N N Y Y.}
}

@slidebreak{InvestigateR}

@ifslide{@image{images/age-stump.png, 180}}

On a decision tree, each branch has to point to a single choice... and right now we have N N N Y Y for teens.

@QandA{
@Q{What prediction should we make for teens? Why?}
@A{They won't buy the game. Because more teens didn't buy the game than did.}
@Q{What predictions should we make for the other age groups?}
@A{People in their twenties and thirties will buy the game.}
}

@slidebreak{Investigate}

@lesson-instruction{
Now that we have our rule, we need to calculate how effectively it predicts the outcomes for our training data. We'll start by placing checkmarks beneath each outcome (Y or N) that our rule would have correctly predicted.
}

@slidebreak{Investigate}

Our rule predicted that individuals in their teens would *not* purchase the game, so:

- We place checkmarks by the Ns that represent Jan, Jose, and Jillian. Our rule was correct for them.
- We leave the Ys without checkmarks; our rule was wrong for Danial and Ariella.

Our rule was correct for 3 out of 5 individuals or 60% of the time.

@lesson-instruction{
- Add checkmarks to the decision tree on @printable-exercise{part-1.adoc} to indicate when our rule was successful for customers in their twenties and thirties.
- Calculate how effectively our rule predicted outcomes for each age group and the dataset as a whole (Question 4).
- Finish the remaining questions in the first section.
}

@slidebreak{InvestigateR}

@center{@image{images/age-stump-checks.png, 180}}

Our rule was pretty effective! It correctly predicted the outcome 10 out of 14 times! And for people in their twenties it was 100% accurate. By utilizing other columns of data, we might be able to make the rule even better! 

There are two possible questions we could use at the next level of our decision tree:

- Is the individual a frequent customer, an infrequent customer, or a new customer?
- Has the individual expressed interest in a particular video game?

@slidebreak{Investigate}

As we move down the tree, our job is to figure out _which questions_ we should ask and _when_ we should ask them... just like when we play 20 Questions! 

@lesson-point{
Decision stumps help us decide which questions produce a greater @vocab{information gain}.
}

@slidebreak{Investigate}

@lesson-instruction{
- Complete the last section of @printable-exercise{part-1.adoc}
- Then complete @printable-exercise{part-2.adoc}.
** You will create and compare different decision stumps for these columns of data.
** The stumps will help you determine which question will produce the biggest information gain.
}

@slidebreak{Investigate}

@QandA{
@Q{Which attributes do you plan to utilize for the second level of the decision tree?}
@A{Interest in Games for Teens}
@A{Shopping History for People in their Thirties}
@A{Since our rule for people in their Twenties was 100% accurate, it will be a leaf node!}
}

@slidebreak{Investigate}

@lesson-instruction{
Complete the first section @printable-exercise{build-and-test.adoc}.
}

@slidebreak{Investigate}

@QandA{
@Q{What rules did you write?}
@A{Interested teens will buy the game}
@A{Everyone in their twenties will by the game.} 
@A{Previous customers in their thirties will by the game.}
}

@slidebreak{Investigate}

@lesson-instruction{
Complete the second and third sections of @printable-exercise{build-and-test.adoc}.
}

@QandA{
@Q{After adding in the test data, what rules would you suggest we change?}
@A{Not all people in their twenties would buy the game. We should probably build decision stumps for people in their twenties for the other available columns and figure out what attribute to add to our tree.}
}

=== Synthesize
@slidebreak{Synthesize}

@QandA{
@Q{What are some reasons that a decision tree might produce an inaccurate prediction or recommendation?}
@A{If the sample is inconsistent and the prediction represents closer to 50% of the sample population than 100% of the population.}
@A{If the tree has been designed to prioritize efficiency over accuracy, it may produce wrong predictions and recommendations.}
@A{If the training dataset does not accurately represent the broader population, predictions and recommendations will be incorrect.}

@Q{After testing our tree, we discovered that it was not as accurate as we might have presumed. Can you think of any examples of when _missing data_ can lead to predictions with serious negative consequences?}
@A{Responses will vary.}
@A{When various populations are underrepresented in training datasets, the resulting technology reflects that, and we end up with AI that fails to meet the needs of those populations.}

@Q{You have learned that @vocab{supervised learning} includes three steps: (1) demonstration of the learning process, (2) function abstraction, and (3) using the function. Describe what each step includes for the @vocab{supervised learning} of a @vocab{decision tree}.}
@A{Demonstration: For decision trees, the demonstration is the labeling of the data so that the computer learns the desired output (or "correct answer") for each data point. During the lesson, we knew whether the individuals in our training set would buy the video game or not.}
@A{Function abstraction: Information gain determines the best way to split data at each node, producing the tree-like structure that can be used to predict outcomes.}
@A{Use: The decision tree predicts outcomes for new, unseen data.}
}



@scrub{
@QandA{
@Q{Why is it advantageous for AI to be efficient?}
@A{Responses will vary, but may include: reduced delays, an improved user experience, greater scalability, decreased environmental impact.}
@Q{Can you think of any reasons *not* to maximize an AI's efficiency?}
@A{Responses will vary, but students will likely observe that an increase in efficiency leads to a decrease in accuracy.}
}

In AI, efficiency and accuracy are often in conflict:

- AI is *efficient* when the computer performs a task with minimal time, memory, energy or data.
- AI is *accurate* when the computer performs its task with correct, relevant, and consistent results.

Striking the perfect balance is an ongoing challenge for computer scientists, and it is a challenge with far-reaching implications.

@QandA{
@Q{Why is it advantageous for AI to be efficient?}
@A{Responses will vary.}
@A{reduced delays}
@A{an improved user experience}
@A{greater scalability}
@A{decreased environmental impact}

@Q{Can you think of any reasons *not* to maximize an AI's efficiency?}
@A{Responses will vary.}
@A{an increase in efficiency leads to a decrease in accuracy.}
}
}