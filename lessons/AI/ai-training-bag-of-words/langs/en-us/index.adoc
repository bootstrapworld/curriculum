[.beta]
= Training Artificial Intelligence: Bag of Words

@description{Students consider what training is by exploring two unique examples: song recommendation and plagiarism detection. As a result of this exploration, they learn that training is the act of transforming data into a model, which is a resource-intensive and time-intensive process.
}

@lesson-prereqs{ai-data-driven-algorithms-spell-checkers}

@keywords{}

[@lesson-intro-table]
|===
| Lesson Goals
| Students will be able to...

@objectives

| Student-facing Lesson Goals
|
- Let's think about training, the act of transforming data into a model.

| Materials
|[.materials-links]
@material-links

| Preparation
| 
@preparation{
- The final section of this lesson involves an activity where students measure the angle difference between rays. 
- If you'd like your students to practice using their protractors, be sure to have have protractors available for @printable-exercise{angle-difference.adoc}. 
- Alternatively, you can have your students estimate angle size using what they know about angle measures and the activity will still be valuable.
}


|===

== Song Recommendation Systems

@objective{training}

=== Overview

Students explore song recommendation, another example of data-driven algorithms at work. Students consider how data aggregation is a key component of machine learning.

=== Launch
@slidebreak{Launch}

@lesson-instruction{
- Read @printable-exercise{case-study-michelle.adoc}.
- Then respond to the questions, providing as much detail as you can.
}

@teacher{Invite students to share their responses.

- If their responses highlight that data-driven algorithms produce a higher quality output when we provide more data--great! Your students understood the key take-away from our @lesson-link{ai-data-driven-algorithms-spell-checkers} lesson.
- Your students might bring new complexity to the conversation by acknowledging the possibility that a programmer's changes to the algorithm could have caused Michelle's increased satisfaction with her play list.
- If your students do *not* propose that Spotify's algorithm was updated (as we suggest in the answer key), that's okay! *There's no need to reveal that possibility immediately.* We recommend moving on with the lesson. After completing @printable-exercise{song-recommending.adoc}, you can circle back to @printable-exercise{case-study-michelle.adoc}.
}

=== Investigate
@slidebreak{Investigate}

It's likely that Michelle could get better suggestions without Spotify making any changes to the code base. But it's also possible that changing the code would improve Michelle's experience!  Let's consider song recommendation in more depth and explore the idea that sometimes _it is helpful for algorithms to change_.

@slidebreak{Investigate}

Very broadly, a song recommendation system does two things:

- collect a user's listening history to build a detailed profile of their musical tastes
- given a new song, determine whether or not to recommend that song

@slidebreak{Investigate}

What does building the profile for a listener entail?

@lesson-instruction{
- With a partner, complete @printable-exercise{song-recommending.adoc}.
- First, you will think about what data could be collected about a song of your choosing.
- Then, you will (informally) design your own song recommendation system!
}

@slidebreak{Investigate}

@QandA{
@Q{What would your song recommendation system's algorithm prioritize?}
@A{Answers will vary!}
}

@slidebreak{Investigate}

As you discovered, song recommendation systems need @vocab{training} in order to make recommendations. 

@lesson-point{@vocab{Training} is the act of transforming data into a model. }

@slidebreak{Investigate}

In machine learning, we generally start with a large chunk of data. A model is then generated from the data. That model is generally expected to be a lot smaller than the original chunk of data (but it may still be huge!). The model can be queried from to get answers.

@slidebreak{Investigate}

In the case of Spotify, the model is a _summary_ of the users' listening habits. Using this model, Spotify answers questions about new, unseen data (e.g. Do we expect Michelle to like the latest Taylor Swift song... or not?).

When Michelle observed that Spotify must have updated its algorithms, she may have been correct...

 - Maybe the algorithm was altered to put more weight on _other_ listeners' behaviors, and less weight on the user's listening behaviors. 
 - Maybe the designer realized they'd left out an important factor in predicting people's musical tastes and the algorithm was completely overhauled!

But we have no way of knowing what actually goes on behind the scenes at Spotify, because 1) these are trade secrets (which companies don't talk about) and 2) there is a huge team actively working on Spotify so how it works could change from day to day! 

@teacher{If your students did not suggest that Spotify improved its algorithms on @printable-exercise{case-study-michelle.adoc}, now is an appropriate time to add some complexity and nuance to the conversation. Discuss the possibility that the algorithm changed a little
or a lot... and that there's no way for us to know!}

=== Synthesize
@slidebreak{Synthesize}

@QandA{
@Q{Why do you think models are generally smaller than the training data?}
@A{Generally, the model *summarizes* the data, eliminating all but its most essential features--the features that enable it to make predictions, generate text, etc.}

@Q{What advantages might there be to the model being smaller than the training data?}
@Q{What disadvantages might there be?}
}

== Bags of Words

@objective{bag-of-words}

=== Overview

Students practice thinking like a hacker to determine the basic requirements of a successful plagiarism detection program. They consider the "bag-of-words" model, which a user can query to better understand how similar or different two documents are.

=== Launch
@slidebreak{Launch}

As a student, you probably know what it feels like to be under surveillance.

- When you use the internet at your school or on a school-issued computer, software probably monitors your web use and blocks you from visiting a multitude of sites.
- When you take a test, it's likely proctored.
- You might even go to a school where adults are stationed around the building and in the hallways or use cameras to check that students are dressed and behaving a certain way.
- When you submit an essay to your English or History teacher, you can expect that they will check for plagiarism - perhaps by running it through a plagiarism detector to be certain that all words and thoughts are your own.

@slidebreak{Launch}

Good designers of these systems have to imagine all the ways that someone might try to _hack_ or _fool_ them. This is called "adversarial thinking". Let's practice thinking like a designer.

@QandA{
@Q{Imagine that your teacher announces that they will be running all student writing through a plagiarism detector and you are a student who wants to plagiarize. Exercise some creativity: What are your strategies for evading detection?}
@A{Responses will vary, but may include the following:
  * replace common words with synonyms
  * change the ordering of sentences and paragraphs
  * plagiarize from an unlikely source (maybe a friend who took the class 5 years ago?)
  * plagiarize from multiple sources
  * paraphrase text so that its tone matches the student's voice
  }
}

@strategy{Adversarial Thinking}{
Go easy on your students! As students share their plagiarism strategies, you may feel judgmental. We urge you to keep those feelings at bay.

In this exercise, we are trying to get students to engage in *Adversarial Thinking* (put simply, thinking like a hacker). This is a valuable strategy that is taught, for example, university courses focused on security, data protection, harms caused by AI, etc. Adversarial Thinking is a valuable skill for students to develop; the key is that they learn how to exercise it in an ethical way!

Just because students excel at thinking in this way doesn't mean they are ethically compromised. Focus on and commend their creativity and reasoning instead of judging them.
}

@slidebreak{Launch-DN}

To understand the workings of plagiarism detection, we'll start by looking at a simple detector.

@lesson-instruction{
- Open the @starter-file{plagiarism}.
- With a partner, complete the first two sections of @printable-exercise{primitive-plagiarism-detector.adoc}.
}

@slidebreak{Launch}

@teacher{Debrief the page with your class using the prompts below.}

@QandA{
@Q{What does the `simple-equality` detector do?}
@A{Takes in two documents and returns `true` if they match exactly and `false` if they don't match exactly.}
@Q{How would you evaluate the effectiveness of the `simple-equality` detector?}
@A{It doesn't work very well! We have no way of knowing how similar the documents are unless they are an exact match. Whether two documents are almost identical or have nothing in common, we will be told that they aren't a match.}
@Q{What might a more effective plagiarism detector do differently?}
@A{Answers will vary.}
}

@slidebreak{Launch}

Plagiarizers usually alter at least a few words of the original document. Sometimes they change the ordering of the text, and sometimes they delete a sentence or word here and there.

- If the `simple-equality` detector finds a match, we can be certain that identicality exists.
- If the detector does not find a match, all we know is that the two documents are not identical.

*We need a more sophisticated plagiarism detector!*

@slidebreak{Launch}

@teacher{The last section of @printable-exercise{primitive-plagiarism-detector.adoc} invites students to think about _measuring similarity_. Remind students about the mountain sorting activity that they completed during @lesson-link{ai-intro} to recontextualize the concept of measuring similarity.}

@lesson-instruction{
- Yara and Xola agree that there has to be a way to measure the _similarity_ of the two essays.
- With a partner, complete the last section of @printable-exercise{primitive-plagiarism-detector.adoc}, where you will consider two proposals for measuring similarity - and then develop your own method for measuring similarity!
}

@slidebreak{Launch}

Rather than detecting identicality, we need to determine the _closeness_ of two documents. To do that, we summarize each document, and then compute the distance between the summaries.

=== Investigate
@slidebreak{Investigate}

One standard way to summarize a document is by creating a @vocab{"bag of words" model}. Let's try it on two documents (below); each document is an example of jazz "scatting", when a vocalist improvises with nonsense syllables.

- *Document a*: "doo be doo be doo"
- *Document b*: "doo doo be doo be"

The bag-of-words summary for *Document a* looks like this: `"be": 2, "doo": 3`

@lesson-point{
A bag-of-words model represents text as an unordered collection of words with their frequencies.
}

@slidebreak{Investigate}

As you can see, we've taken the original sentence and disregarded word order, creating a collection that focuses solely on *word frequency*.

@QandA{
@Q{What is the bag-of-words summary for *Document b*?}
@A{The bag-of-words summary for Document b looks like this: `"be": 2, "doo": 3`.}
@A{It should be identical to the bag-of-words summary for Document a.}
@Q{How did you know what order to put the words in?}
@A{I used the same order as the bag-of-words summary for Document a.}
}

_Note: We could have written these bag-of-words summaries as `"doo": 3, "be": 2`, but once we decide on a word order for one document, adhering to that same order is required. The simplest way to be consistent is to use alphabetical order._

The bag-of-words summary for both documents is exactly the same!

@slidebreak{Investigate-DN}

A plagiarism detector that uses this model, taking stock of word frequency and word order, could compare the bags instead of the documents. If it did so, it would conclude that the two bags of words are a perfect match... and that Document a and Document b are suspiciously similar.

@lesson-instruction{
- Open the @starter-file{plagiarism}.
- With a partner, complete @printable-exercise{slightly-less-primitive-detector.adoc}.
}

@slidebreak{Investigate}

@QandA{
@Q{How is the `bag-equality` plagiarism detector different from our primitive `simple-equality` plagiarism detector?}
@A{The `bag-equality` plagiarism detector compares two bag-of-words summaries, rather than simply comparing two texts.}

@Q{How is the `bag-equality` plagiarism detector similar to our primitive `simple-equality` plagiarism detector?}
@A{Like our primitive plagiarism detector, it checks for identicality. It determines if the two bags of words are identical or not.}
}

Checking if two bags of words are identical *is* an improvement from checking if two texts are identical.

=== Synthesize
@slidebreak{Synthesize}

@QandA{
@Q{What similarities are there between a system that recommends songs and `bag-equality` plagiarism detection?}
@A{Both systems build summaries of the available data and then work with those summaries.}

@Q{Can you think of any other apps or technologies that _measure similarity_ in some way?}

@A{Image retrieval - finding images similar to a given image from a large database}
@A{Facial recognition - identifying and verifying individuals based on facial features}
@A{Product recommendation - suggesting items for purchase based on a customer's browsing history}

}


== Data Normalization

@objective{data-normalization}

=== Overview

Students explore the importance of @vocab{data normalization}, when we organize data to follow a standard pattern.

=== Launch
@slidebreak{Launch}

Here are some discoveries we have made so far:

- Checking if two texts are identical is not an effective way of detecting plagiarism.
- Summarizing documents as bags of words, and _then_ checking for identicality is better than comparing two texts... but it is also not an effective way of detecting plagiarism.

@slidebreak{LaunchC}

What we need is a way to check if bags are _similar_!

One strategy programmers use for this is to represent bags of words as points in space.

Let's see how that would work for Documents a and b.

- We already know that *Document a* "doo be doo be doo" can be represented as the bag of words (`"be": 2, "doo": 3`).
- Written as a coordinate pair, it would like this: (2, 3)
- Plotting that point on the be-doo plane looks like this:

@center{@image{images/3-2.png, 150}}

When we plot a point on the _coordinate_ plane, we typically locate @math{x} on the horizontal axis and @math{y} on the vertical axis. Similarly, bags must use same word order if we want meaningful results. 

@QandA{
@Q{How would you represent Document b ("doo doo be doo be") as a point on the be-doo plane?}
@A{The point would be in the exact same position as the point for Document a.}
@A{Because we decided on "be" then "doo" for Document a, we must use "be" then "doo" for Document b also.}
}

The decision we just made - to use "be" then "doo" for both bags of words - is an example of @vocab{data normalization}. Data normalization is the act of adapting and modifying disparate data so that they all have the same characteristics (making them easy to compare and otherwise compute with).

@lesson-point{
Don't skip data normalization! 
}

Failure to normalize data can lead to useless and confusing outputs.

=== Investigate
@slidebreak{Investigate}

Let's look at some slightly more complicated documents and consider how to plot their points in a multi-dimensional space.

- Document c: "doo be doo be doo doo doo"
- Document d: "be bop bop bop be bop bop"

[cols="1,2,2", options="header", stripes="none"]
|===
| Document
| Bag-of-words summary
| Point

| c
| `"be": 2, "doo": 5`
| (2, 5)

| d
| `"be": 2, "bop": 5`
| (2, 5)
|===

*We have a problem.*  We can plainly see that Documents c and d are *not* the same ... but their points are...

@QandA{
@Q{What went wrong here?}
@A{The point is to draw out student thinking here rather than to get to any particular answer. The remainder of the lesson will dig into the details. Students might suggest:
 * The points were written as if there were only two items in the list... but, in fact there are three different items!
 * 5 represents "doo" in the first point and "bop" in the second point... but we've lost that information.
}
}

In the example above, we forgot the @vocab{data normalization}. How can we fix it?

@slidebreak{InvestigateC}

To solve this problem, let's start by taking a closer look at our data.

- Document c: "doo be doo be doo doo doo"
- Document d: "be bop bop bop be bop bop"

[cols="3a,^4a, 4a", grid="none", frame="none"]
|===
|
When we use a Venn Diagram to visualize the data...
| @image{images/scat-venn-diagram.png, 150}
|...we recognize that Documents c and d +
contain a total of *three different words*!
|===

@lesson-point{
Because there are three words, we need to use a *three* dimensional space, rather than a coordinate plane, which has just two dimensions. 
}

@slidebreak{InvestigateR}

We must revise our bag-of-words summaries and our points!

@ifslide{
- Document c: "doo be doo be doo doo doo"
- Document d: "be bop bop bop be bop bop"
}

[cols="1,2,2", options="header", stripes="none"]
|===
| Document
| Bag-of-words summary
| Point

| c
| `"be": 2, "bop": 0, "doo": 5`
| (2, 0, 5)

| d
| `"be": 2, "bop": 5, "doo": 0`
| (2, 5, 0)
|===


Normalizing data requires that we consider _all_ the words; when a word occurs zero times in a document, we acknowledge it. Instead of glossing over the dimension, we indicate that a given word occurred zero times. When we include *all* of the words from both documents, we produce a model with the correct @vocab{dimensionality}. For the bag-of-words model, the dimensionality equals how many different words are in the corpus.

It is a bit trickier to envision plotting these points, but not impossible!

@QandA{
@Q{@right{@image{images/2pts.png, 150}}In the 3-dimensional space to the right, which point represents @math{c}?}
@A{The one on the bottom.} 
@Q{How do you know?}
@A{It's at point (2,5) on the be-doo plane, and has moved 0 in the bop direction.}
}

Let's recap:

- We started out with two documents. 
- Now, in place of our two documents, we have two points that exist at specific locations in a multi-dimensional space.
- We are going to think about how to make use of those points very soon...

@lesson-instruction{
- But first, let's practice!
- Complete @printable-exercise{plotting-bows.adoc}, where you will convert text documents into bags of words, and then plot points to represent those bags.
- You will also get an opportunity to _reverse_ the process. (You will convert plotted points into bags and text!)
}

@teacher{Once students have completed @printable-exercise{plotting-bows.adoc}, reflect on the activity by discussing the prompts below.}

@QandA{
@Q{Which cells on @printable-exercise{plotting-bows.adoc} had more than one correct solution? Why?}
@A{When we were asked to write the _text_ when given either an ordered pair or a bag-of-words summary, multiple solutions were possible.}
@A{For instance, in row I, "be doo doo" and "doo be doo" would both be correct responses.}
@A{Multiple responses are correct in these instances because the bag-of-words model eliminates word order.}

@Q{Who do you agree with, Sierra or Jaden?}
@A{Students can reasonably agree with either Sierra or Jaden, depending on whether they think the _specific lyrics_ define song A, or if its repetitive nature is what defines song A.}
@A{Some students may contest that it is too difficult to determine similarity with such limited information - also a valid point.}
@A{If your students discuss the actual distance of the different points on the coordinate plane, they are thinking like programmers!}
}

=== Synthesize
@slidebreak{Synthesize}

@QandA{
@Q{Earlier in the lesson, you learned that generally, models _summarize_ the data, eliminating all but the most essential features. Which features of the starting document does the bag of words eliminate? Which features does it preserve?}
@A{The bag-of-words model eliminates word order. It preserves word count.}

@Q{Why is it important for the bag-of-words summary to acknowledge when a word occurs zero times?}
@A{Each point exists in a multi-dimensional space. To compare points and consider their closeness, the points must exist in the same multi-dimensional space. When we omit a word that occurs zero times, we are in fact omitting a dimension and constructing a broken model.}
}


== Computing Closeness with Angle Difference

=== Overview

Compressing text into bags of words gives us a coarse-grained notion of similarity. Let's explore how to produce a more refined notion of similarity.

=== Launch
@slidebreak{Launch}

When we ask people whether two documents are the same, they rarely give us a black-and-white "yes" or "no" answer. Instead they tend to speak about shades of similarity. Likewise, we would like our computer to give us a range of values that give us a sense of how similar the two documents are. In other words, we would like the output to be a Number, not just a Boolean (identical, not identical).

=== Investigate
@slidebreak{Investigate}

Now that we know how to represent our bag of words summaries as points in space, we can draw a @vocab{ray} from the origin through each of those points and ask: What is the angle between the two rays?

Take, for example, this comparison between two strings: `stringA` ("doo doo doo doo") and `stringB` ("be be be be").

[cols="<.^8a,<.^8a,<.>8a",  stripes="none"]
|===
|
`StringA`: `doo doo doo doo`
[cols="1,1",options="header"]
!===
! Word  ! Frequency
! be ! 0
! doo! 4
!===
Ordered pair: (0,4)
|
`StringB`: `be be be be`
[cols="1,1",options="header"]
!===
! Word  ! Frequency
! be ! 4
! doo! 0
!===
Ordered pair: (4,0)
|

@center{@image{images/soln1.png, 150}}

The angle formed is 90°.
|===

@slidebreak{Investigate}

If two documents are identical, they will be at the same point in space, and have the same ray extending from the origin to that point. That means the angle between those rays will be 0°. Even if one document just rearranges the other, their bags of words will be identical—thereby again making the angle between the lines 0°.

@lesson-instruction{
- Complete @printable-exercise{angle-difference.adoc} using your knowledge of bags of words and plotting points.
** First, fill in the frequency tables by referring to the provided string.
** Translate the bags of words to ordered pairs.
** Plot the points.
** Draw a ray from the origin to each of the points.
** Approximate the angle size.
}

@slidebreak{Investigate}

As the documents contain different words, the angles between the lines will grow. To reflect this, we can use the `angle-difference` function. It will give us a value between 0° (if the two are identical) and 90° (if the two have nothing in common).

@strategy{Points, Rays, and Vectors}{
As you've discovered, our plagiarism detector computes the angle difference between rays extending from the origin to various points that we have plotted space.

In machine learning, we generally refer to these bag-of-word representations *not* as _points_, but as _vectors_. Why? A point represents a location in space, whereas a vector represents a magnitude and a direction.

To reduce the amount of new vocabulary introduced in this lesson, we have opted to refer simply to points and rays. More commonly, however, the term _vector_ is used in a machine learning context.

If you or your students are wondering why we wouldn't just compute the _distance_ between points, rather than complicating things and introducing angles... it's because typically, machine learning uses vectors, not points.
}

The contract for `angle-difference` is below.

```
# angle-difference :: (String, String) -> Number
```

@slidebreak{Investigate-DN}

@lesson-instruction{
Let's try the `angle-difference` function in Pyret.

- Check your work on @printable-exercise{angle-difference.adoc}.
.
** Open @starter-file{plagiarism} and click "Run".
** Enter `angle-difference("doo doo doo doo", "be be be be")` into the Interactions Area.
** Does the angle size that Pyret produces match the angle that you drew? (Hopefully yes!)
** Use `angle-difference` to compare each pair of strings on @printable-exercise{angle-difference.adoc}.
}

@strategy{Angles?!}{

Yes, angles!

Did you know that geometry is at the heart of modern AI? This lesson shows how. The same angles that your students learn to compute in middle-school are sitting at the heart of the machine learning calculations that power so many things in the world today. Even the plagiarism detectors that might be checking their essays on angles... are computing angles. So if your students ask “When are we ever going to use this?”, you can tell them, “You already do, all the time.”

The plot thickens, especially if you have older students who have learned some trigonometry. In practice, real machine learning systems don't _quite_ use angles. Instead, they use the cosine of the angle. There are two reasons for this:

- The angle itself is a somewhat awkward value to work with. In contrast, the cosine has a nice numeric range, between -1 and 1, which makes it convenient to use in various other mathematical settings. (Specifically, it's used in a process called gradient descent.)

- It’s simpler to compute the cosine directly. In fact, inside Pyret, `angle-difference` actually first computes the cosine, then converts the result into an angle!

For the purposes of this curriculum, you can ignore this difference. In particular, if your students have never even heard of the cosine, that's fine! For students who are familiar with cosine and curious to explore, the @starter-file{plagiarism} contains a `cosine-similarity function`.
}

=== Synthesize
@slidebreak{Synthesize}

@QandA{
Here are three different lines of code.

`angle-difference("hello world", "hello")`

`angle-difference("hello", "goodbye")`

`angle-difference("hello", "hello")`

@Q{Which line of code produces 90°? How do you know?}
@A{`angle-difference("hello", "goodbye")`; the two strings are completely different.}

@Q{Which line of code produces 45°? How do you know?}
@A{`angle-difference("hello world", "hello")`; the two strings have one word in common; they are not entirely different nor are they identical.}

@Q{Which line of code produces 0°? How do you know?}
@A{`angle-difference("hello", "hello")`; the two strings are exactly the same.}
}

