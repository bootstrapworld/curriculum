= Decision Tree: Level 1

[.linkInstructions]#Use the @handout{decision-tree-data.adoc, "training data"} to respond to the prompts below.# Let's investigate what happens when we begin our tree with "age" as the root.

== Predicting Shopping Behavior by "age"

@n Let's look at the "buys game" and "age" columns of the training dataset and see what we can learn about each age group's purchasing habits.

@indented{
[cols=".^1a, .^10a", stripes="none", grid="none", frame="none"]
|===
|teens:
| @fitbruby{7em}{@ifsoln{2}}{# who bought} out of @fitbruby{7em}{@ifsoln{5}}{# in age group} individuals buy the game.
|twenties:
| @fitbruby{7em}{@ifsoln{4}}{# who bought} out of @fitbruby{7em}{@ifsoln{4}}{# in age group} individuals buy the game.
| thirties:
| @fitbruby{7em}{@ifsoln{3}}{# who bought} out of @fitbruby{7em}{@ifsoln{5}}{# in age group} individuals buy the game.
|===
}

@n Let's use what we've learned to write our rule. Predict that:

@indented{
- individuals in their @fitbruby{15em}{@ifsoln{twenties}}{teens / twenties / thirties} and in their @fitbruby{15em}{@ifsoln{thirties}}{teens / twenties / thirties} will buy the game.
- individuals in their @fitbruby{15em}{@ifsoln{teens}}{teens / twenties / thirties} will not buy the game.
}

== Decision Stumps

Below is a "decision stump" representing the distribution of all of the "age" data in the dataset. It's called a stump because it has just one level. You'll notice that it branches three ways (each with a yes/no) rather than the simple forks we've seen in previous decision trees.

@n Place checkmarks below each of the values that the computer would predict correctly.

@ifnotsoln{@center{@image{../images/stump.png, 200}}}

@ifsoln{@center{@image{../images/age-stump-checks.png, 170}}}

@n A computer following this rule for our training data would make @fitb{3em}{@ifsoln{10}} correct predictions out of 14 attempts (@fitb{3em}{@ifsoln{71}} % accuracy).

@n If we used the decision tree stump above to make predictions, find the likelihood of a correct prediction for each age group.

@hspace{3em} teenage shopper: 	@fitb{5em}{@ifsoln{60}}%
@hspace{3em} shopper in their twenties: @fitb{5em}{@ifsoln{100}}%
@hspace{3em}shopper in their thirties:@fitb{5em}{@ifsoln{60}}%

@n Which (if any) of the leaf nodes for "age" are pure? (_Pure_ means that the leaf contains exclusively one single value.) @fitb{}{@ifsoln{"twenties"}}

== Branching Again

@n Before moving on to the second level of his decision tree, Ernie removed all of the rows for people in their twenties. As Bert watched Ernie grab a pencil and cross out those rows, he said,

@vspace{1ex}

@indented{_"I don't think that's a good idea! Why would we alter our dataset just because we're starting the second level of the tree?"_}

Explain Ernie's (correct) decision to Bert. @fitb{}{@ifsoln{Since all customers in their twenties buy the game, it's a leaf node,}}

@fitb{}{@ifsoln{which means there won't be any branches for these rows to train the AI to make decisions for.}}

@n We need to decide which column it makes most sense to branch to after our "teens" and "thirties" decision nodes. What are our choices?

@indented{@fitbruby{15em}{@ifsoln{interest in game}}{[column]} or @fitbruby{15em}{@ifsoln{shopping history}}{[column]}}
