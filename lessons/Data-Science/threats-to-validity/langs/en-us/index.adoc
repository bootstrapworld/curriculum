= Threats to Validity

@description{Students consider possible threats to the validity of their analysis. _This lesson optionally includes the @lesson-link{project-threats}_üé®.}

@lesson-prereqs{ds-intro}

@keywords{}

[@lesson-intro-table]
|===
| Lesson Goals
| Students will be able to...

@objectives


| Student-facing Lesson Goals
|

- Let's identify issues that could affect our data analysis.

| Materials
|[.materials-links]
--
_*This lesson is unplugged* and does not require a computer._

@material-links
--
| Supplemental Materials
|[.materials-links]
@opt-material-links
- @lesson-link{project-threats}

| Classroom Visual
| - @handout{pages/Geckoboard-Data-Fallacies-Poster.pdf, Poster of Data Fallacies to Avoid} _from geckoboard.com/best-practice/statistical-fallacies/_

| Preparation
|
@preparation{
- There is an optional kinesthetic activity in this lesson that requires a ball of play-dough for each group of 3.
- There is an activity in this lesson that requires students to make a copy of a google doc, add 4 data visualizations from their Pyret dataset and make false claims about it. Then they are to tried documents with a classmate and try to identify why each other's claims are misleading. If you have a printer in the classroom, it probably makes most sense for students to print their documents and physically trade them with a classmate. If not, you'll want to think about whether it makes most sense for them to submit them to you so you can print them for another day or whether you'd like them to share the files with you and each other electronically.
}

| Optional Project
|
- @lesson-link{project-threats}: Students pretend to be terrible data scientists who develop and support claims based on faulty sampling techniques (selection bias, bias in the study design, poor choice of summary data, and confounding variables). This is a fun opportunity for your students to demonstrate their understanding of the impact of various threats to validity.

| Assessments
| @assessments

|===

== Threats to Validity
@objective{threats-demonstrate}


=== Overview
Students are introduced to the concept of @vocab{validity}, and a number of possible threats that might make an analysis invalid.

=== Launch
@slidebreak{Launch}

As good Data Scientists, the staff at the animal shelter are constantly gathering data about their animals, their volunteers, and the people who come to visit. 

But just because they have data doesn‚Äôt mean the conclusions they draw from it are correct! 

@slidebreak{Launch}

@lesson-instruction{
Suppose the shelter staff surveyed 1,000 cat-owners and found that 95% of them thought cats were the best pet. 

Could they really claim that people generally prefer cats to dogs?
}

@slidebreak{Launch}

@lesson-point{
There‚Äôs more to data analysis than simply collecting data and crunching numbers.
} 

In the example of the cat-owning survey, the claim that ‚Äúpeople prefer cats to dogs‚Äù is *invalid* because the data itself wasn‚Äôt representative of the whole population (of _course_ cat-owners are partial to cats!).

@slidebreak{Launch}

*Data Scientists have several major @vocab{Threats to Validity} to worry about:*

*1) Selection bias* -- Data was gathered from a sample that is not representative of the population.

  * This is the problem with surveying _cat owners_ to find out which animal is most loved!

@slidebreak{Launch}

*2) Bias in the study design* -- Data was gathered in such a way that it influenced the results, for example, researchers might:

  * Phrasing a question to manipulate people's answers. For example: ‚ÄúSince annual vet care comes to about $300 for dogs and only about half of that for cats, would you say that owning a cat is less of a burden than owning a dog?‚Äù This could easily lead to a misrepresentation of people‚Äôs true opinions.
  * Ask a series of questions in a way that changes the way respondents might answer the last question. Intentionally asking questions about controversial topics at the beginning might get respondents angry, which could influence the way they answer a question at the end.
  * Judge other cultures on the standards of their own culture rather than the standards of the one being studied. This is known as "culture bias".

@ifslide{@teacher{The list continues on the next slide.}}
@slidebreak{Launch}

*3) Poor choice of summary data* -- Even if the selection is unbiased, sometimes outliers are so extreme that they make the mean completely useless at best -- and misleading at worst. For example:

  * If you're trying to get a sense of the wealth of a typical family in a community, averaging in the wealth of a few billionaires will skew the results.

*4) Confounding variables* -- Sometimes there's an unaccounted for variable that is lurking in the background, influencing both of the variables we are studying and confusing the relationship between them. For example:

  * A study might find that cat owners are more likely to use public transportation than dog owners. But it's not that owning a cat means you drive less: people who live in big cities are more likely to use public transportation, _and_ also more likely to own cats.

@teacher{
More examples of @vocab{confounding variables} can be found in the @lesson-link{correlations, correlations lesson}: @opt-printable-exercise{correlations/pages/correlation-is-not-causation.adoc}.
}

And there are many other threats to validity out there!

=== Investigate
@slidebreak{Investigate}

@lesson-instruction{
- On @printable-exercise{threats-to-validity-1.adoc} and @printable-exercise{threats-to-validity-2.adoc}, you‚Äôll find four different claims backed by four different datasets.
- Each one of those claims suffers from a serious threat to validity. 
- Work with your partner to identify each of the four threats.
- @opt{Respond to @opt-printable-exercise{selection-bias-v-biased-study.adoc}}
}

@slidebreak{Investigate}

Life is messy, and there are _always_ threats to validity. 

Data Science is about doing the best you can to _minimize_ those threats, and to be upfront about what they are whenever you publish a finding.

When you do your own analysis, make sure you include a discussion of possible threats to validity!

=== Synthesize
@slidebreak{Synthesize}

Why is it important to consider potential threats to validity?


== Fake News and the Misuse of Statistics
@objective{misuse-identify}


=== Overview
Students are asked to consider the ways in which statistics are misused in popular culture, and become critical consumers of some statistical claims. Finally, they are given the opportunity to misuse their _own_ statistics, to better understand how someone might distort data for their own ends.

=== Launch
@slidebreak{Launch}

You have already seen a number of ways that statistics can be misused:

*1) Using the wrong measure of center* with heavily-skewed data

*2) Using a correlation to imply causation*

*3) Incorrect Interpretations* of a visualization, which try to trick people who don't know how to read charts and graphs. For example:

- A reporter telling us that the @math{r}-value in linear regression is telling us "the percent chance" of something happening.
- A politician telling us that the tallest bar in a _bar chart_ makes up the largest percentage of the whole sample.
- An advertisement telling us that the tallest bar in a _histogram_ makes up the largest percentage of the whole sample.

@slidebreak{Launch}

There are many other ways to mislead the audience, including:

*4) Intentionally using the wrong chart* -- Suppose someone was asked to prepare a report on the demographics of the people holding positions of power in their city government. If the city had a significant Black population, and no Black elected officials, it should be cause for further investigation. But, if someone were trying to avoid addressing the issue, they might opt to display a pie chart (hiding that lack of representation) instead of displaying a bar chart (that would show an empty bar) in hopes that nobody would even notice the issue! Note: Pie charts could be used responsibly for this same scenario if a pie chart displaying the demographics of the city's population was presented alongside a pie chart of the demographics of the city's elected officials!

*5) Changing the scale of a chart* -- Changing the y-axis of a scatter plot can make the slope of the regression line seem smaller ("look, that line is basically flat anyway!") or larger ("look how quickly things have changed!").

With all the news being shared through newspapers, television, radio, and social media, it‚Äôs important to be critical consumers of information!

=== Investigate
@slidebreak{Investigate-DN}
@lesson-instruction{
- On @printable-exercise{fake-news.adoc}, you‚Äôll find some deliberately misleading claims made by slimy Data Scientists. 
  * Identify why each of these claims should not be trusted.
- Once you‚Äôve finished, make a copy of @starter-file{lies}.
  * Come up with four misleading claims based on data or visualizations from your dataset.
  * Fit it on one page, print and trade with another group. See if you can figure out why each other‚Äôs claims are not to be trusted!
- @opt{If you want more practice debunking Fake News, complete @opt-printable-exercise{fake-news-2.adoc}.}
}

@QandA{
@Q{What "lies" did you tell?}
@Q{Was anyone able to stump the other group?}
}

=== Synthesize
@slidebreak{Synthesize}

- Where have you seen statistics misused in the real world?
- Over the next several weeks, keep your eyes peeled for misused statistics and bring the examples you find to class to share!


== Dealing with Outliers
@objective{outlier-impact}

=== Overview
Students are confronted with the concept of _outliers:_ data points that stray far from the rest of the data and appear to confound observed patterns and groupings. Data Scientists take the decision of whether or not to keep outliers very seriously, as there can be profound implications for validity.

=== Launch
@slidebreak{LaunchR}
@right{@image{images/height-outlier.png, 300}}Suppose we survey the heights of 12-year-olds, and almost all values are clustered between 50-70in. There's a very low outlier, however, at 6in.

@QandA{
@Q{Is there really a 12-year-old who is 6 inches tall?}
@A{Probably not! This is almost certainly junk data from a typo (maybe someone meant to type "60" instead of "6"?).}
}

@slidebreak{LaunchR}
@ifslide{@right{@image{images/height-outlier.png, 300}}}
This typo could throw off our analysis completely! This one data point will destroy the mean, forcing us to use a different measure of center even if the rest of the data is symmetric.

"Junk" data is harmful, because it can drastically change our results! If we blindly keep every outlier, it can become a serious threat to the validity of our analysis!

@slidebreak{LaunchR}

@right{@image{images/stadium-outlier.png, 300}}Suppose we survey the number of minutes it takes for fans to find their seats at a stadium, and almost all values are clustered between 4-16 minutes. There's a very high outlier, however, at 35 minutes.

@QandA{
@Q{Did it really take someone 35 minutes to find their seat?}
@A{It's very possible! Maybe it's someone who takes a long time getting up stairs, or someone who had to go far out of their way to use the wheelchair ramp!}
}

@slidebreak{LaunchR}
@ifslide{@right{@image{images/stadium-outlier.png, 300}}}
If we choose to _remove_ or _keep_ an outlier without thinking carefully, it can become a serious threat to the validity of our analysis!

=== Investigate
@slidebreak{Investigate}
@lesson-point{Outliers... do they stay or do they go?}

As a data scientist, an outlier is _always a reason to look closer_. And whether you decide to keep or remove it from your dataset, make sure you explain your reasons in your write-up!

@lesson-instruction{
With your partner, complete @printable-exercise{outliers-discussion.adoc}.
}

These points are called _unusual observations_. Unusual observations in a scatter plot are like outliers in a histogram or dot plot, but more complicated because it‚Äôs the _combination_ of x and y values that makes them stand apart from the rest of the cloud.

@slidebreak{Investigate}

@lesson-point{Unusual observations are _always_ worth thinking about!}

Sometimes unusual observations are _just random_. Felix seems to have been adopted quickly, considering how much he weighs. Maybe he just met the right family early, or maybe we find out he lives nearby, got lost and his family came to get him. In that case, we might need to do some deep thinking about whether or not it‚Äôs appropriate to remove him from our dataset.
@slidebreak{Investigate}

Sometimes unusual observations can give you a _deeper insight_ into your data. Maybe Felix is a special, popular (and heavy!) breed of cat, and we discover that our dataset is missing an important column for breed!

@slidebreak{Investigate}

Sometimes unusual observations _are the points we are looking for!_ What if we wanted to know which restaurants are a good value, and which are rip-offs? We could make a scatter plot of restaurant reviews vs. prices, and look for an observation that‚Äôs high above the rest of the points. That would be a restaurant whose reviews are unusually good for the price. An observation way below the cloud would be a really bad deal.

=== Synthesize
@slidebreak{Synthesize}

@QandA{
The school cafeteria surveyed 100 students about their favorite foods, and most chose things like pizza, spaghetti, Caesar salad, etc. But two students chose foods that no one else heard of!
@Q{What are some reasons why these outliers should _stay?_}
@A{These students might have important dietary restrictions that need to be taken into consideration!}
@Q{What are some reasons why these outliers should _go?_}
@A{What if those foods aren't real, and the two students were just messing around?}
}

@slidebreak{Synthesize}

@QandA{
@Q{If Data Scientists are the ones deciding whether an outlier is important or irrelevant, why does it matter _who_ those Data Scientists are?}
@A{A Data Scientist might be biased for or against a specific group or idea, and be more likely discard outliers they _don't_ or keep those they _do_ like.}
@A{A Data Scientist might simply be unfamiliar with the domain of the data they're analyzing, and not realize whether an outlier is important and needs to be kept!}
}

@teacher{
This is a great opportunity to remind students that @lesson-link{computing-needs-all-voices}!

Want to check student mastery of the content you've just taught? Administer @assessment{threats-to-validity, Show What You Know: Threats to Validity}.
}
