= Ethics, Privacy, and Bias

@description{Students consider ethical issues and privacy in the context of data science.}

@lesson-prereqs{ds-intro}

@keywords{ethics, privacy, bias}

[@lesson-intro-table]
|===
| Lesson Goals
| Students will be able to...

@objectives
@objective{Describe ethical and privacy considerations when it comes to data science}

| Student-facing Lesson Goals
|

* Let's discuss ethical concerns surrounding data science.

| Materials
| _*This lesson is unplugged* and does not require a computer._

[.materials-links]
@material-links

|===

== Case Studies

=== Overview
Students break into groups and read one of three case studies, each dealing with a different issue in Data Science. They discuss the implications of each, then share back.

=== Launch
@slidebreak{LaunchR}

@right{@image{images/AtomicBomb.png, 150}}

*(1) Should scientists be bound by any ethical rules? If so, what rules?*

During World War II, scientists were engaged in a race to develop new weapons, more powerful than anything the world had ever seen. While the immediate goal was "win the war", many of the scientists realized that the weapons they were developing could be used for all sorts of things _after the war was over_ -- and not all of them were good.

@clear

@slidebreak{Launch}

*(2) Should doctors be bound by any ethical rules? If so, what rules?*

History is filled with examples of those who study science -- be it medicine, human behavior, psychology, etc. -- ignoring their ethical responsibility as humans. For example: 

  * Between 1932 and 1972, doctors in the U.S. studied nearly 400 African American men with syphillis, as part of an experiment about the longterm effects of the disease going untreated, @link{https://en.Wikipedia.org/wiki/Tuskegee_Syphilis_Study, without informing the men that treatment was widely available and they would never be treated}. 
  * In 1971, researchers at Stanford conducted an @link{https://en.Wikipedia.org/wiki/Stanford_prison_experiment, experiment in human behavior that went horribly wrong, causing tremendous damage to their participants}.



@slidebreak{Launch}

*(3) Should data scientists be bound by any ethical rules? If so, what rules?*

With tech companies hiring Data Scientists at a staggering rate and collecting massive datasets on users for those scientists to mine, there's a _new_ arms race happening right now. Search engines tailor their results based on what they know about the customer doing the search, and social media networks recommend friends based on what they know about all of us.

Both goals require building profiles on everyone, figuring out what their preferences are and where they tend to spend their time. They might require figuring out whether each of us is young or old, more likely to go to a movie or a play, or about to buy sneakers or a phone.

@slidebreak{Launch}

But these datasets and profiles could be used for far more than that. What if the FBI used them to try and figure out who is likely to commit a crime, or a company tries to learn their employees' religion or sexual orientation?

As they build ever-more sophisticated models based on ever-more accurate datasets, Data Scientists need to think about the ethics of what they're doing as well!

=== Investigate
@slidebreak{Investigate}

@lesson-instruction{
- In your group of 3-4 students, complete @printable-exercise{CaseStudy.adoc} on one of the articles below.
  * @online-exercise{https://www.forbes.com/sites/kashmirhill/2012/02/16/how-target-figured-out-a-teen-girl-was-pregnant-before-her-father-did/#68ca57a66686, How Target Figured Out A Teen Girl Was Pregnant Before Her Father Did}
  * @online-exercise{https://www.CNN.com/2013/03/11/tech/social-media/facebook-likes-study/index.html, Facebook 'likes' can Reveal Your Secrets}
  * @online-exercise{https://www.ProPublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing, Algorithmic Bias in Criminal Sentencing}
  * @online-exercise{https://veritenews.org/2025/04/10/tiger-algorithm-louisiana-parole-calvin-alexander/, An algorithm deemed this nearly blind 70-year-old prisoner a ‘moderate risk.’ Now he’s no longer eligible for parole.}
- After your group completes the worksheet, one person from each group will share back with the class what your group learned.
}

@teacher{The third article is quite long, but only the first half is needed for students to complete this activity.}

=== Synthesize
@slidebreak{Synthesize}
Give students time to discuss and share back. Encourage students to share back differing views on the articles.

@QandA{
@Q{What are some commonalities among the issues raised by these articles?}
@A{Data collected about us and others like us is being used to make predictions about our future behavior, whether that be what ads we'll be susceptible to or how likely we are to commit crimes.}
@A{People are not fully aware of how data is being used to construct profiles abou them.}
@A{People are not always comfortable with how much companies know about them from their shopping history, etc.}

@Q{What are some differences among the issues raised by these articles?}
@A{No harm is done if target sends us an ad we aren't interested in.}
@A{Deciding how to sentence someone based on racially-biased algorithms locks low risk people up and frees high risk people to commit more crimes.}
}

== Additional Exercises
@slidebreak{Supplemental}

- Generate a list of "Rules for Ethical Data Science"?
- Write a one-page essay about your thoughts on the future of AI.
- Read this article on @link{https://www.statnews.com/2020/06/17/racial-bias-skews-algorithms-widely-used-to-guide-patient-care/, Racial Bias in Algorithms used to determine Medical Care}. Write arguments for or against health care providers using algorithms to make medical decisions. You may even want to host a debate, giving students a chance to make "opening" and "closing" arguments, taking turns so that the closer for each side can respond to what the other side said.
- Watch or read CBS News Coverage from when @link{https://www.CBSnews.com/news/microsoft-shuts-down-ai-chatbot-after-it-turned-into-racist-nazi/, Microsoft Shut Down its AI Teen Chatbot after it made Racist Tweets} and write a response.
