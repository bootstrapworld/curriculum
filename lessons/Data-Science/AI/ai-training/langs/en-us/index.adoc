= Training Artificial Intelligence

@description{Students consider what training is by exploring two unique examples: song recommendation and plagiarism detection. As a result of this exploration, they learn that training, a resource-intensive and time-intensive process, is the act of transforming data into a model.
}

@ifproglang{pyret}{
@lesson-prereqs{ai-data-driven-algorithms}
}

@keywords{}

[@lesson-intro-table]
|===
| Lesson Goals
| Students will be able to...

@objectives

| Student-facing Lesson Goals
|

Let's think about training, the act of transforming data into a model.

| Materials
|[.materials-links]
@material-links

|===


== Song Recommendation Systems

@objective{training}

=== Overview

Students explore song recommendation, another example of data-driven algorithms at work. Students consider how data aggregation is a key component of machine learning.

=== Launch

Data is at the heart of data science, and--as you learned during the previous lesson--@vocab{data-driven algorithms} are at the heart of AI. This statement is true of spell checkers, which we explored, along with many other types of programs that employ machine learning.

While it is true that providing _more_ data often produces better results, we must also consider how other variables can influence the quality of output.

@lesson-instruction{
- Read @printable-exercise{case-study-michelle.adoc} and respond to the questions, providing as much detail as you can.
}

@teacher{Invite students to share their responses.

If their responses highlight that data-driven algorithms produce a higher quality output when we provide more data--great! Your students understood the key take-away from @lesson-link{ai-data-driven-algorithms, "the previous lesson"}.

You probably noticed that the solutions on @printable-exercise{case-study-michelle.adoc} bring new complexity to the conversation by acknowledging the possibility that *programmer interference* could be the cause of Michelle's increased satisfaction with her play list.

If your students do *not* propose that the Spotify's algorithm was updated (as we suggest in the answer key), that's okay! *There's no need to reveal that possibility immediately.* We recommend moving on with the lesson. After completing @printable-exercise{song-recommending.adoc}, you can circle back to @printable-exercise{case-study-michelle.adoc}.
}

=== Investigate

For Michelle to get better results, changing the code is not necessarily needed... although it is always a possibility! Let's consider song recommendation in more depth, and explore the idea that sometimes, _there is a need for algorithms to change_.

Very broadly, a song recommendation system does two things:

- it has some knowledge of what the listener already likes
- given a new song, it determines whether or not to recommend that song

In order for Spotify to do the predictive work that we expect (step 2, above), storing a list of Michelle's music is insufficient! Instead, the program must _aggregate_ her listening history: that is, over time, Spotify builds a detailed profile of each user's musical tastes. But what does that entail?

@lesson-instruction{
- With a partner, complete @printable-exercise{song-recommending.adoc}.
- First, you will think about different metadata that can be collected and stored.
- Then, you will (informally) design your own song recommendation system!
}

@vocab{Training} is the act of transforming data into a model. As you discovered, song recommendation systems need @vocab{training} in order to make recommendations. In the case of Spotify, the model is a _summary_ of the user's listening habits. Using this model, Spotify can answer questions about new, unseen data (e.g., will Michelle like the latest Taylor Swift song... or not?).

@teacher{If your students did not suggest that Spotify improved its algorithms on @printable-exercise{case-study-michelle.adoc}, now is an appropriate time to add some complexity and nuance to the conversation. Be sure to discuss all of the possibilities that we outline in the solutions: perhaps the model changed a little, or perhaps the model changed a lot... there's no way for us to know!}

=== Synthesize

@QandA{

@Q{In machine learning, we generally start with a large chunk of data. A model is then generated from the data. That model is generally expected to be a lot smaller than the original chunk of data (but it may still be huge!). The model can be queried from to get answers. *Why do you think models are generally smaller than the training data?*}

@A{Generally, the model *summarizes* the data, eliminating all but its most essential features--the features that enable it to make predictions, generate text, etc.}
}


== Build a Bag of Words

@objective{bag-of-words}

=== Overview

Students engage in adversarial thinking to determine the basic requirements of a successful plagiarism detection program. They consider the "bag-of-words" model, which a user can query to better understand how similar or different two different documents are.

=== Launch

As a student, you probably know what it feels like to be under surveillance.

- When you enter your school, adults are stationed around the building and in the hallways. You might even go to a school that uses cameras to check that students are dressed and behaving a certain way.
- When you use the internet at your school or on a school-issued computer, software monitors your web use and blocks you from visiting a multitude of sites.
- When you submit an essay to your English teacher, you can expect that they will check for plagiarism - perhaps by running it through a plagiarism detector to be certain that all words and thoughts are your own.

Sure, these surveillance tactics have their purposes... but being constantly watched is exhausting! Let's turn the tables and see if we can _beat_ one method of surveillance: the plagiarism detector.

To ground our conversation, we will consider a very important question: Is it possible to _fool_ a plagiarism detector?

@QandA{
- Your teacher announces that they will be running all student writing through a plagiarism detector.
- You are a student who wants to plagiarize.
- Exercise some creativity: What are your strategies for evading detection?
}

@strategy{Adversarial Thinking}{
Go easy on your students! As students share their plagiarism strategies, you may feel judgmental. We urge you to keep those feelings at bay.

In this exercise, we are trying to get students to engage in *Adversarial Thinking* (put simply, thinking like a hacker). This is a valuable strategy that is taught, for example, in cybersecurity courses at the university level. Security, data protection, and even consideration of the harms caused by AI—these all require adversarial thinking skills. Adversarial Thinking is a valuable skill for students to develop; the key is that they learn how to exercise it in an ethical way!

Instead of concluding that students who excel at thinking in this way are ethically compromised, consider commending their creativity and reasoning.
}

To understand the workings of plagiarism detection, we'll start by looking at a simple detector that _does not work very well_. First, it consumes documents from the internet. Next, we feed it a student student-submitted document. It compares the student document against the others to determine if there is a match.

@lesson-instruction{
- Open the @starter-file{plagiarism}.
- With a partner, complete @printable-exercise{primitive-plagiarism-detector.adoc}.
}

If the plagiarism detector finds a match, we can be certain that an identical document exists. If the detector does not find a match, we know that there are no identical documents. _Either way, we can't draw any conclusions about whether plagiarism happened!_

As we discussed, plagiarizers usually alter at least a few words of the original document. Sometimes they change the ordering of the text, and sometimes they delete a sentence or word here and there. *We need a plagiarism detector with more sophistication!*

=== Investigate

Detecting identicality is not good enough. We need a different approach. We need to determine the _closeness_ of two documents. To do that, we need a way to summarize each document, and then compute the distance between the summaries.

One standard way to summarize a document is by creating a "bag of words" model. Let's look at two documents (below). Each is an example of jazz "scatting", when a vocalist improvises with nonsense syllables.

- Document a: "doo be doo be doo"
- Document b: "doo doo be doo be"

The bag-of-words summary for Document A looks like this: `"doo": 3, "be": 2`

As you can see, we've taken the original sentence and disregarded word order, creating a collection that focuses solely on *word frequency*.

With our bag of words, we have actually created a @vocab{vector} where each word represents one axis.


@lesson-point{
A @vocab{vector} is an ordered list of numbers within parentheses and separated by commas, representing a point.
}

Using vector notation, we can represent Document a like this: @math{\overrightarrow{a} = (3, 2)}

@teacher{
Some students may conclude that @math{\overrightarrow{a} = (3, 2)}, while others may argue that @math{\overrightarrow{a} = (2, 3)}. Order does not matter in a Bag of Words... but we do need to _choose_ an order that we will use for all of the vectors in the space.
}

If we were to plot a point for the vector on the coordinate plane, it would produce this:

@center{@image{images/3-2.png, 150}}

@QandA{
@Q{What is the bag-of-words summary for Document b?}
@A{The bag-of-words summary for Document b looks like this: `"doo": 3, "be": 2`. It should be identical to the bag-of-words summary for Document a; `"be": 2, "doo": 3` is also acceptable! Adhering to the same word order is required.}

@Q{How would you represent the vector for Document b on the coordinate plane?}
@A{The point would be in the exact same position as the point for Document a. When we plot a point on the coordinate plane, first we plot @math{x} and then we plot @math{y}. There is no such protocol with the bag-of-words model. That said, it is crucial to adhere to the _same word order_ for each Bag of Words. Because we decided on "doo" then "be" for document a, we must use "doo" then "be" for document b also.}
}

@lesson-point{
A bag-of-words model represents text as an unordered collection of words with frequencies.
}

The bag-of-words summary for both documents is exactly the same! When the program takes stock of word frequency and ignores literally everything else, the two models are a perfect match: each one results in a point on the coordinate plane at @math{(3,2)}.

=== Synthesize

@QandA{

The bag-of-words model is better at detecting plagiarism than the primitive plagiarism detector—but it's not perfect.

@Q{What kind of plagiarism _can_ we catch using this model?}
@A{We can catch a plagiarizer who reorders the words a document.}

@Q{What sort of plagiarism are we still _unable_ to catch?}
@A{We cannot catch a plagiarizer who _alters_ the words in a document by substituting in synonyms or changing word tense.}

@Q{What might we _misidentify_ as plagiarism using this model? Put another way, what sort of _non-plagiarism_ might be labeled _plagiarism_?}
@A{Someone might independently write a text with a Bag of Words that happens to be quite close to the Bag of Words for a different text. This coincidence is more likely with shorter documents. Returning to our Documents a and b: scatting jazz vocalists are not commonly accused of stealing one another's material.}
}


== Normalize Data and Consider Dimensionality

@objective{data-normalization}

=== Overview

Students explore the importance of normalizing data, removing unneeded characteristics and eliminating redundancy.

=== Launch


Documents a and b were relatively simple. Because we used a total of two words, we needed only two axes to plot our vectors—the "be" axis and the "doo" axis.

Let's look at some slightly more complicated documents:

- Document c: "doo be doo be doo doo doo"

- Document d: "be bop bop bop be bop bop"


[cols="1,2,2", options="header", stripes="none"]
|===

| Document
| Bag-of-words summary
| Vector

| c
| `"doo": 5, "be": 2`
| @math{\overrightarrow{c} = (5, 2)}

| d
| `"bop": 5, "be": 2`
| @math{\overrightarrow{d} = (5, 2)}

|===

*We have a problem.*  We can plainly see that Documents c and d are *not* the same ... but their vectors are. _What went wrong here?_

@teacher{
Something definitely went wrong! The table above demonstrates the student error of *forgetting to normalize data and consider dimensionality*. Students discover what these entail during the lesson.
}

=== Investigate

To solve this problem, let's start by taking a closer look at our data.

First we must recognize that between Documents c and d there are *three* different words. Because there are three words, we need to use a *three* dimensional space, rather than a coordinate plane, which has just two dimensions. We can use a Venn Diagram to visualize our corpus:

@center{@image{images/scat-venn-diagram.png, 150}}

We must revise our bag-of-words summaries and our vectors!

@teacher{Normalizing data and considering dimensionality requires that--when a word occurs zero times--we acknowledge it. Instead of glossing over the dimension, we indicate that a given word occurred zero times.}

The new bag-of-words summary for Document c is `"doo": 5, "be": 2, "bop": 0`, which we can represent as  @math{\overrightarrow{c} = (5, 2, 0)}.

The new bag-of-words summary for Document d is `"doo": 0, "be": 2, "bop": 5`, and we can represent it as @math{\overrightarrow{d} = (0, 2, 5)}.

@right{@image{images/2pts.png, 200}}

It is a bit trickier to envision plotting these vectors, but not impossible!

For @math{\overrightarrow{c}}, envision a sheet of paper resting on a table. Plot @math{(5, 2)} on that sheet of paper: move 5 units to the right of the origin and then 2 units up. Because the z-coordinate is 0, the piece of paper *stays on the table.*

For @math{\overrightarrow{d}}, again envision a sheet of paper resting on a table. Plot @math{(0, 2)} on that sheet of paper by moving 2 units along the y-axis above the origin. Because the z-coordinate is 5, we imagine lifting the sheet of paper off the table and increasing its height (z) by 5-units.

@lesson-point{
Training is the act of transforming *data* into a *model*.
}

We started out with two documents. Now that our training is complete, in place of our two documents, we have two points that exist at specific locations in a multi-dimensional space.

We are ready to put our model to use!

=== Synthesize


@QandA{
@Q{Earlier in the lesson, you learned that generally, models _summarize_ the data, eliminating all but the most essential features. Which features of the starting document does the bag of words eliminate? Which features does it preserve?}

@A{The bag of words model eliminates word order. It preserves word count.}

@Q{Why is it important for the bag-of-words summary to acknowledge when a word occurs zero times?}

@A{Each vector exists in a multi-dimensional space. To compare vectors and consider their closeness, the vectors must exist in the same multi-dimensional space. When we omitting a word that occurs zero times, we are in fact omitting a dimension and constructing a broken model.}
}


== Compute Closeness and Exercise Human Judgment

=== Overview

Students investigate the limitations of plagiarism detection, acknowledging the importance of exercising human judgment.

=== Launch

The training phase is now complete. Let's review what has happened so far.

*1. We created bag-of-words models of our documents.*

In doing so, we compressed the data by isolating the single feature that we care about: word frequency. As a result, the _new_ representation of the data became considerably smaller than the actual corpus.

@lesson-point{
Loss of data is a common and often necessary effect of training AI!
}

*2. We normalized our data.*

Comparisons are most useful when we are comparing items that are alike. When building bags of words for the documents in the corpus, each model *must* have the same number of words (dimensions!) regardless of how many words are in a given document. Defaulting to a cliche: we need an "apples-to-apples" comparison, rather than an "apples-to-oranges" comparison. This is why we include in some models words that we did not encounter in a given document.

What now?

=== Investigate

Our primitive plagiarism detector determined if two documents matched perfectly. That plagiarism detector was not especially useful.

A _more_ effective plagiarism detector will compute the student's vector (a point in a multi-dimensional space), and then compare it to the _other_ points in that space.

To do this, we can use the `cosine-similarity` function.

@strategy{That Cosine?!}{

You might be wondering: are we actually using *that* cosine—the one students learn about when studying trigonometry? The answer is YES!

The `cosine-similarity` function computes the cosine of the angle between two vectors. While it is not necessary for students to understand the mathematics happening behind the scenes, the function is a vital part of the program... and a lovely answer to the often-asked question, "Where are we ever going to use this?"
}

To allow for a pleasant user experience, a modern plagiarism detector does not actually provide a representation of a multi-dimensional space with varying points. That would be too complicated! Although different plagiarism detectors provide different outputs for their users, here's how the one in Pyret works.

- The `cosine-similarity` function takes in two strings (documents).
- The plagiarism detector produces an output of 1 when the vectors are identical.
- The plagiarism detector produces an output of zero when the vectors are entirely different.
- The plagiarism detector produces a value between zero and 1 for all other comparisons, reflecting the level of similarity of two bags of words.

@lesson-instruction{
- Complete the first section of @printable-exercise{human-judgment.adoc}, where you will evaluate the closeness of the student essay and the wikipedia article using the cosine-similarity function.
- Complete the remaining two sections of @printable-exercise{human-judgment.adoc}, where you will consider four possible outputs of a plagiarism detector that utilizes the cosine similarity function.
}

@teacher{
Invite students to share their responses.}

=== Synthesize

@QandA{

@Q{AI can be impressive... but human judgment is still critical. Why?}

@A{The cosine-similarity function produces a number - and that is all! It is still up to the teacher to decide how to make sense of that number. Over-reliance on programs can result in unfair outcomes.}


@Q{Now that you understand a little bit more about how plagiarism detection programs work, what advice would you offer to a teacher who is considering using one... or to a student who is trying to get away with plagiarism?}
}
