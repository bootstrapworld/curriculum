= Fitting Models

@description{Students learn about model "fitness" through the _S_ value (Standard Deviation of Residuals).}

@lesson-prereqs{correlations}

@keywords{linear, slope, intercept, slope-intercept, S, Sres, error}

@add-to-lang{fit-model, S}

[@lesson-intro-table]
|===

| Lesson Goals
| Students will be able to...

-
-

| Student-facing Lesson Goals
|

-


| Materials
|[.materials-links]
@material-links

| Supplemental Materials
|[.materials-links]
@opt-material-links


| Key Points For The Facilitator
|
-


|===

== Line of "Good" Fit?

=== Overview
Students confront the notion of "model fitness". How do we measure how well a model fits? How do we determine which of two models is best? They consider two models for a simple dataset and brainstorm how we could measure which fits better.

=== Launch

Let's return to the animals dataset, and see if there's a correlation between an animal's `age` and the `weeks` to adoption.

@lesson-instruction{
- Open the @starter-file{fitting-animals}.
- Make a scatter plot, using the animals' `name` as the labels, their weight in `pounds` as the @vocab{explanatory variable} on the x-axis, and the `weeks` it took to be adopted as the @vocab{response variable} on the y-axis.
}

@slidebreak

@center{@image{images/scatter-plot-lizard-sample-weeks-v-pounds.png}}

@QandA{
@Q{Does there appear to be a relationship here? If so, how would you describe it?}
@A{Solicit student answers, facilitate discussion.}
@A{It looks like weeks to adoption decreases as the lizards get heavier.}
}

@strategy{Teaching Tip}{

Project the scatter plot at the front of the room, and have students come up to point out their patterns.
}

@slidebreak

@lesson-instruction{
- One way to summarize the relationship we see in a scatter plot is to draw the @vocab{line of best fit}. 
- In your mind's eye, consider where you might draw a line on this scatter plot to summarize the trend you see in the data.
}

=== Investigate

If two people both think there's a linear relationship hiding in this data, they might each see a _different_ linear relationship. 

@lesson-instruction{
- Turn to @printable-exercise{how-could-we-measure-good-fit-lizard.adoc} and use a straight edge to draw a line that you think would fit the data well on the scatter plot.
- Then, complete the questions on the page with your partner.
}

=== Synthesize

@QandA{
@Q{What criteria did you come up with for how to assess whether or not a model is a good fit for the data?}
@A{Answers will vary. Ideas might include:}
@A{The points should be as evenly distributed around the model as possible.
- We could see how the number of points above the line and below the line compare.
- We could measure the distance between the points and the line and try to make sure the average distance above is balanced with the average distance below.}

@Q{How could we measure the distance between the data points and the linear model?}
@A{Answers will vary. Ideas might include:}
@A{By drawing vertical lines connecting each data points to the linear model.}
@A{By drawing horizontal lines connecting each data points to the linear model.}
@A{By drawing diagonal lines connecting each data points to the linear model. +
Push students to recognize that in order for this measurement to be useful they would have to be perpendicular to the linear model!}
@A{By drawing squares with one corner on the data point and the opposite corner on the linear model.}
}

== Introducing @math{S}

=== Overview

Students test out their linear models using a Pyret function called `fit-model`, which draws the residuals and computes the Standard Deviation of the Residuals (@math{S}).

=== Launch

Pyret has a special function called `fit-model` that takes in a function and graphs it on top of a scatter plot.

@QandA{
@Q{Take a look at the contract for `fit-model` in your @dist-link{Contracts.shtml, contracts page}. +
What is its Domain?}
@A{Like `scatter-plot`, it consumes columns for our _labels_, our @math{x}s, our @math{y}s... *additionally, it _consumes a function_*.}
}

@slidebreak

@lesson-instruction{
- Open the @starter-file{fitting-animals} and click "Run" to test out `fit-model` with the dataset and functions you were just looking at.
- What do you Notice? What do you Wonder?
}

@ifnotslide{
[cols="1a,1a", frame="none", grid="none"]
|===
| `fit-model(lizard-sample, "name", "pounds", "weeks", f)`
| `fit-model(lizard-sample, "name", "pounds", "weeks", g)`

| @centered-image{images/fit-f.png}
| @centered-image{images/fit-g.png}
|===
}

@slidebreak

@right{@image{images/residual.png, 200}}When you graph your model in Pyret, you can see that:

- some of the points are close to the line ("real" @math{y} is close to "predicted" @math{y})
- some points are quite far away ("real" @math{y} is far from "predicted" @math{y})

The difference between any real @math{y} and predicted @math{y} is called the @vocab{residual}, and it measures how far off that one point in the model is from the actual data. The smaller the residuals, the better a model fits!

@slidebreak

@QandA{
@Q{There are three terms in the legend at the bottom. What do they refer to?}
@A{The blue line is the model.}
@A{The red dots are the data from the data set.}
@A{Residuals refer to the vertical black lines connecting the data points to the model, representing the distance between the data and the value the model predicts. They vary in length depending on how far above or below the model the data is situated.}

@Q{Compare the `fit-model` display for `f` to the `fit-model` display for `g`. How are they similar? How are they different?}
@A{The x-axis goes from 0 to 8 for both of them.}
@A{The y-axis for `f` is numbered 3 to 9. It goes from 0 to 20 for `g`.}
@A{Both `f` and `g` have a blue line and red dots.}
@A{`f` has significantly more red dots below the blue line than above it.}
@A{The data points for `f` more or less fill the vertical space of the display, whereas for `g` there are only data points in the bottom half of the display.}

@Q{How do @math{S} and @math{r-sqr} compare for the two models?}
@A{The values are positive for both models and both @math{S} and @math{R^2} values are smaller for `f` than they are for `g`.}

@Q{Based on the @vocab{S} values of the plots you created on this page, what do you think @vocab{S} means?}
@A{Answers will vary, but students should have some sense of the idea that if one model has a lower @vocab{S} value than another model of the same data it indicates a better fit.}
}

@slidebreak
@ifslide{@right{@image{images/residual.png, 200}}}
There are many different tools to calculate the fitness of a model. You may have heard of @math{R}, @math{R^2}, etc...

Statisticians and Data Scientists are careful to use the right tool for the job!

- We want a measure of _error_, so the measure should be zero for a perfect model with no residuals.
- We want a measure that's easy to understand, so in our case it should measure _how many income-dollars of error_ a model has.
- We want a measure that takes the residuals from _every_ data point into account.

@slidebreak

@ifslide{ @right{@image{images/residual.png, 200}} }@vocab{S} is a measure of fitness, which refers to the @vocab{Standard Deviation of the Residuals}.

- The closer the data points are to the model, the smaller the residuals are.
- Smaller residuals mean a smaller @vocab{S}, and a better model!
- We know that if a model fits the data perfectly, the @vocab{S} value would be 0.
- Unlike other measures of fitness, @vocab{S} is expressed in terms of _units of the y-axis_. An @vocab{S} of `5` in this dataset means _the standard deviation of the residuals is 5 weeks_ - making it much easier to understand.

@slidebreak

@lesson-point{
The @math{S}-value always has to be considered in the context of the range of values that the model is predicting!
}


@lesson-instruction{
- Turn to @printable-exercise{s-tells-us.adoc}.
- Consider the @math{S}-value of each model in the context of the range of the data described.
- Decide how well the model is likely to predict values.
}

@QandA{
@Q{Were any of the models described terrific? How do you know?}
@A{Both 2 and 8}
@A{Because the numbers in the range were huge and the @math{S} value was really small.}

@Q{Were any of the models described terrible? How do you know?}
@A{Both 1 and 6}
@A{Because the @math{S}-value was big in comparison to the range.}
@A{For the first scenario the @math{S}-value was 300, which was the majority of the range between 0 and 400.}
@A{For the sixth scenario, even though the @math{S}-value was only 1, it was much bigger than any of the numbers in the range, which maxed out at two hundredths.}
}


@strategy{Optional: Which Model is Best?}{
If students know how to compute the equation of a line that crosses between two points, use @opt-printable-exercise{lines-to-functions.adoc} to have them define their models for `age` v. `weeks` in Pyret and use `fit-model` to see which one is best.
}

=== Synthesize

- TODO

== Additional Practice

For more practice deciding and articulating which model is better, have your students complete @opt-printable-exercise{how-could-we-measure-good-fit-cheerios.adoc}. They can then practice fitting the models to test their work using the @opt-starter-file{alg2-cheerios}.

@ifnotslide{
[cols="1a,1a", frame="none", grid="none"]
|===
| `fit-model(cheerios-table, "id", "day", "cheerios-on-the-floor", f)`
| `fit-model(cheerios-table, "id", "day", "cheerios-on-the-floor", g)`

| @centered-image{images/cheerios-f.png}
| @centered-image{images/cheerios-g.png}
|===
}
