= Fitting Periodic Models

@description{Having deciphered the patterns in a dataset with perfect periodic (sinusoidal) behavior, students build and work with a model for data about Carbon Dioxide that has more variability.}

@lesson-prereqs{periodic2-building-models}

@keywords{periodic, period, amplitude, frequency}

[@lesson-intro-table]
|===

| Lesson Goals
| Students will be able to...

- Read and interpret real-world data, presented in a scatter plot
- Model periodic relationships using functions

| Student-facing Lesson Goals
|

- Let's use Pyret to model periodic relationships in data.

| Materials
|[.materials-links]
@material-links

|===

== Fitting Periodic Models
@objective{model-explore}

=== Overview
Students explore the @math{\text{CO}_2} dataset, which tracks the recorded quantity of carbon dioxide in the atmosphere from the Mauna Loa observatory in Hawaii beginning in 1974.

=== Launch
The Ferris wheel dataset we looked had almost no variability: the wheel doesn't change size or speed, and there aren't any other variables influencing the data. As a result, our scatter plot lines up perfectly with a periodic model. This is pretty rare in the real world!

Now that we've had some practice, let's take a look at a dataset that has more variability.

Carbon Dioxide (@math{\text{CO}_2}) is:

- the gas inside the bubbles in a can of soda
- what we breathe out when we exhale
- dry ice (in solid form)
- known as a "greenhouse gas", because, when enough of it is in the atmosphere, it traps heat and contributes to global warming

@slidebreak

Because scientists are concerned about how much @math{\text{CO}_2} is in the atmosphere, they take frequent measurements from multiple locations around the globe. The amount of @math{\text{CO}_2} in the atmosphere is measured in _parts-per-million_, abbreviated as _ppm_. There are many things that can influence the amount of @math{\text{CO}_2} in any one location over the course of time. Some of these factors include:

- temperature and air pressure
- proximity to carbon-dioxide-producing sources or carbon-dioxide-consuming features
- global trends like the burning of fossil fuels

But is there a pattern?

@slidebreak

@lesson-instruction{
- Open the @starter-file{alg2-co2}.
- Save a copy that's just for you, and click "Run".
}

@QandA{
@Q{What is the name of the table here?}
@A{co2-table}
@Q{What are the names of the columns?}
@A{year, month, data, co2}
@Q{Type `co2-table` into the Interactions Area, and look at the table. +
What do the `year`, `month`, and `co2` columns mean?}
@A{`year` is pretty self-explanatory, e.g. 1974 in the first row indicates that the first measurement was recorded in the year 1974.}
@A{`month` is a number from 1 to 12. The 5 in the first row corresponds to May.}
@A{`co2` is the carbon dioxide level in parts per million as measured at the Mauna Loa Observatory in Hawaii. In May of 1974 they recorded 333.18 ppm of @math{\text{CO}_2}.}
@Q{The numbers in the `date` column look pretty different from dates we are used to seeing. What do they tell us?}
@A{See the *decimal year* explanation below. If you're using the slidedeck, advance to the next slide!}
}

@slidebreak

The `date` column provides us with something known as the *decimal year*. When reading a *decimal year*, we see the year followed by the decimal that results when the __n__th day of the year is divided by 365.

@teacher{For inquiring students, you may need to know that during a leap year, the decimal year is calculated by dividing by 366. (1974 was not a leap year. The next leap year was 1976.)}

@QandA{
The first date is `1974.375`, meaning the sample was taken `0.375` of the way through 1974.
@Q{How could we compute which day of the year that is?}
@A{There are 365 days in the year, so we could multiply 365 by `0.375` to see the number of days into the calendar.}
@A{@math{365 \times 0.375 = 136.875}, or roughly day 137}
@Q{Does that day correspond to the "month-number" in the `month` column for the first row?}
@A{Yes. The 137th day of the year is May 16th or 17th, depending on whether or not it is leap year and May is the 5th month.}
}


@slidebreak

@lesson-instruction{
- Now that we know what each of the columns mean, take another look at the dataset.
- What do you *Notice*?
- What do you *Wonder*?
}

Let's turn our attention back to the Definitions Area. Find the function `is-recent`.

@QandA{
@Q{What does `is-recent` do?}
@A{It takes in a row, and checks to see if the decimal date is between 2022.083 and 2023.7917.}
@Q{What is defined on the line of code that follows?}
@A{A table, which contains only the rows for which the filter function produces `true`: just the rows between those dates.}
}

@slidebreak

The `recent-table` includes just the rows from valley-to-valley for the years 2022-2023. It defines a single period.

=== Investigate
@lesson-instruction{
- Complete @printable-exercise{modeling-recent-co2.adoc} using the @starter-file{alg2-co2}.
- Be ready to share your answers!
}

@slidebreak

@QandA{
@Q{What was the highest @math{\text{CO}_2} value in the table? The lowest?}
@A{424 and 415.74 parts per million.}
@Q{What did you get for @vocab{amplitude} @math{a}?}
@A{4.13, because the distance between the high and low readings is 8.26.}
@Q{What did you get for the @vocab{vertical shift} @math{k}?}
@A{Adding the amplitude (4.13) to the lowest value (415.74) gives us 419.87.}
@Q{What did you estimate for the @vocab{phase shift} @math{d}?}
@A{Answers will vary, but should be close to 2023.1}
@Q{How many years make up one @vocab{period}?}
@A{One year (this makes sense, since the seasonal cycle repeats every year!)}
@Q{What did you get for @vocab{frequency} @math{b}?}
@A{@math{2\pi}, because the period is 1 year and @math{{2\pi \over 1} = 2\pi}.}
@Q{What does this frequency tell us?}
@A{TO DO}
}

@slidebreak

@lesson-instruction{
- Let's use these values to construct our `periodic` model, and then fit our model to the data in Pyret!
- With your partner, complete *the first section* on @printable-exercise{modeling-recent-co2-2.adoc}.
}

@slidebreak

@QandA{
@Q{When you look at the `periodic` model graphed on the `recent-table` scatter plot, do you think it makes sense to use a periodic model for this data? Why or why not?}
@A{Yes. The data points move up and down along either side of the curve.}
@Q{How does this model for the @math{\text{CO}_2} data compare to the model we saw for the ferris wheel data?}
@A{All of the points for the ferris wheel data fell on the curve.}
@A{Our @math{\text{CO}_2} data falls near the curve, but not on it.}
@Q{According to the @vocab{S-value}, how well does your `periodic` model fit the data in the `recent-table`?}
@A{We expect an error of about 1.2 ppm of @math{\text{CO}_2} and the data in the `recent-table` ranges from 415.91 to 424, which means the model is a fairly good fit.}
@Q{Linear regression allows us to find the *computationally optimal model*, not just a model that "fit really well." Do we know whether or not our model is the _best?_}
@A{We don't know!}
}

@slidebreak

@lesson-instruction{
- Let's see how well our model fits the @math{\text{CO}_2} data from other years.
- With your partner complete @printable-exercise{modeling-recent-co2-2.adoc}.
}

@QandA{
@Q{How does the shape of our model compare to the shape of the data from the `modern-table`?}
@A{Answers will vary. Sample responses may include:
 - While they both have a wave, they look pretty different!
 - The model undulates around a horizontal line and the data undulates around a diagonal line.
 - The y-intercepts are in completely different places.
}
@Q{What do the S-values tell us about how the error we expect for predictions made from our `periodic` model for the data in the `modern-table` compares to the error we expect for predictions made for the data in the `recent-table`?}
@A{It is much more significant!}
@Q{What are some problems you see with this model?}
@Q{Where does it fit the data best?}
@A{Within the range of the dataset that it was built on.}
@Q{Where does it fit the worst?}
@A{The farther we get from the date range it was built on.}
}

=== Synthesize

We just built a model from a sample for predicting @math{\text{CO}_2} levels and then tried to use it to model a larger dataset.

@QandA{
@Q{Why might data scientists build a model from a sample?}
@A{In the real world it is pretty rare to have access to every piece of data we can imagine wanting to work with, so sometimes all we have is a sample.}

@Q{What limitations are there to building a model from a sample?}
@A{The predictions a model will make will be most accurate for the range of data it is built on. Data beyond that range might exhibit other trends.}
@A{The pattern we find in a sample could be unrepresentative of the patterns in the whole.}
}

== Additional Exercises

@strategy{Optional Activity: Guess the Model!}{

1. Divide students into teams of 2-4, and have each team come up with a periodic, real-world scenario, then have them write down a periodic function that fits this scenario on a sticky note. Make sure no one else can see the function!
2. On the board or some flip-chart paper, have each team draw a _scatter plot_ for which their periodic function is best fit. They should only draw the point cloud - _not the function itself!_ Finally, students title their scatter plot to describe their real-world scenario (e.g. - "Water depth at a beach vs. Time of Day").
3. Have teams switch places or rotate, so that each team is in front of another team's scatter plot. Have them figure out the original function, write their best guess on a sticky note, and stick it next to the plot.
4. Have teams return to their original scatter plot, and look at the model their colleagues guessed. How close were they? What strategies did the class use to figure out the model?

- The coefficients can be constrained to make the activity easier or harder. For example, limiting these coefficients to whole numbers, positive numbers, etc.
- To extend the activity, have the teams continue rotating so that each group adds their sticky note for the best-guess model. Then do a gallery walk so that students can reflect: were the models all pretty close? All over the place? Were the guesses for one coefficient grouped more tightly than the guesses for another?
}


